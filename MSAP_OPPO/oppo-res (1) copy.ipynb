{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-11T06:21:00.751900Z","iopub.status.busy":"2024-02-11T06:21:00.751525Z","iopub.status.idle":"2024-02-11T06:21:01.116701Z","shell.execute_reply":"2024-02-11T06:21:01.115800Z","shell.execute_reply.started":"2024-02-11T06:21:00.751869Z"},"metadata":{},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:01.119651Z","iopub.status.busy":"2024-02-11T06:21:01.118847Z","iopub.status.idle":"2024-02-11T06:21:01.124444Z","shell.execute_reply":"2024-02-11T06:21:01.123048Z","shell.execute_reply.started":"2024-02-11T06:21:01.119616Z"},"metadata":{},"trusted":true},"outputs":[],"source":["# x_train_path = \"/kaggle/input/wisdm-data/wisdm/x_train.npy\"\n","# y_train_path = \"/kaggle/input/wisdm-data/wisdm/y_train.npy\"\n","x_train_path = \"/root/HAR/dataset/OPPORTUNITY/x_train.npy\"\n","y_train_path = \"/root/HAR/dataset/OPPORTUNITY/y_train.npy\"\n","# x_test_path = \"/kaggle/input/wisdm-data/wisdm/x_test.npy\"\n","# y_test_path = \"/kaggle/input/wisdm-data/wisdm/y_test.npy\"\n","x_test_path = \"/root/HAR/dataset/OPPORTUNITY/x_test.npy\"\n","y_test_path = \"/root/HAR/dataset/OPPORTUNITY/y_test.npy\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:01.126163Z","iopub.status.busy":"2024-02-11T06:21:01.125884Z","iopub.status.idle":"2024-02-11T06:21:04.273964Z","shell.execute_reply":"2024-02-11T06:21:04.273176Z","shell.execute_reply.started":"2024-02-11T06:21:01.126139Z"},"metadata":{},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SEModule(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.fc1 = nn.Conv1d(channels, channels // reduction, kernel_size=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv1d(channels // reduction, channels, kernel_size=1, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        y = self.avg_pool(x)\n","        y = self.fc1(y)\n","        y = self.relu(y)\n","        y = self.fc2(y)\n","        y = self.sigmoid(y)\n","        return x * y\n","\n","\n","class ChannelAttention1d(nn.Module):\n","\n","    def __init__(self, in_channels, ratio=16):\n","        super(ChannelAttention1d, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.max_pool = nn.AdaptiveMaxPool1d(1)\n","\n","        self.fc1 = nn.Conv1d(in_channels, in_channels//16, 1, bias=False)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Conv1d(in_channels//16, in_channels, 1, bias=False)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n","        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n","        out = avg_out + max_out\n","        return self.sigmoid(out)\n","\n","class SpatialAttention1d(nn.Module):\n","\n","    def __init__(self, kernel_size=3):\n","        super(SpatialAttention1d, self).__init__()\n","        self.conv = nn.Conv1d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv(x)\n","        return self.sigmoid(x)\n","\n","class rSoftMax(nn.Module):\n","    def __init__(self, radix, cardinality):\n","        super().__init__()\n","        self.radix = radix\n","        self.cardinality = cardinality\n","\n","    def forward(self, x):\n","        if self.radix > 1:\n","            batch = x.size(0)\n","            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n","            x = F.softmax(x, dim=1)\n","            x = x.reshape(batch, -1)\n","        else:\n","            x = torch.sigmoid(x)\n","        return x\n","\n","\n","class DropBlock1D(object):\n","    def __init__(self, *args, **kwargs):\n","        raise NotImplementedError\n","\n","\n","class SplAtConv1d(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            channels,\n","            kernel_size,\n","            stride=1,\n","            padding=0,\n","            dilation=1,\n","            groups=1,\n","            bias=True,\n","            radix=2,\n","            reduction_factor=4,\n","            norm_layer=None,\n","            dropblock_prob=0.0,\n","            **kwargs,\n","\n","    ):\n","        super().__init__()\n","\n","        self.dropblock_prob = dropblock_prob\n","        inter_channels = max(in_channels * radix // reduction_factor, 32)\n","        self.radix = radix\n","        self.cardinality = groups\n","        self.channels = channels\n","\n","        self.conv = nn.Conv1d(\n","            in_channels,\n","            channels * radix,\n","            kernel_size,\n","            stride,\n","            padding,\n","            dilation,\n","            groups=groups * radix,\n","            bias=bias,\n","            **kwargs,\n","        )\n","        self.bn0 = norm_layer(self.channels * radix)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc1 = nn.Conv1d(self.channels, inter_channels, 1, groups=self.cardinality)\n","        self.bn1 = norm_layer(inter_channels)\n","        self.fc2 = nn.Conv1d(inter_channels, self.channels * radix, 1, groups=self.cardinality)\n","        if dropblock_prob > 0.0:\n","            self.dropblock = DropBlock1D(dropblock_prob, 3)\n","        self.rsoftmax = rSoftMax(radix, self.cardinality)\n","        self.se = SEModule(in_channels)\n","        self.ca1 = ChannelAttention1d(in_channels)\n","        self.sa1 = SpatialAttention1d()\n","\n","    def forward(self, x):\n","        #x = self.ca1(x) * x\n","        #x=  self.sa1(x) * x\n","        #x = self.se(x) * x\n","        x = self.conv(x)\n","        x = self.bn0(x)\n","        if self.dropblock_prob > 0.0:\n","            x = self.dropblock(x)\n","        x = self.relu(x)\n","\n","        batch, rchannel = x.shape[:2]\n","        if self.radix > 1:\n","            splited = torch.split(x, int(rchannel // self.radix), dim=1)\n","            gap = sum(splited)\n","        else:\n","            gap = x\n","        #se放在这个位置结果非常好\n","        #位置1，通道注意力\n","        gap = self.ca1(gap) * gap\n","        #gap = self.sa1(gap) * gap\n","        #gap = self.se(gap) * gap\n","        gap = F.adaptive_avg_pool1d(gap, 1)\n","        gap = self.fc1(gap)\n","        gap = self.bn1(gap)\n","        gap = self.relu(gap)\n","\n","        atten = self.fc2(gap)\n","        atten = self.rsoftmax(atten).view(batch, -1, 1)\n","\n","        if self.radix > 1:\n","            attens = torch.split(atten, int(rchannel // self.radix), dim=1)\n","            outs = []\n","            for att, split in zip(attens, splited):\n","                outs.append(att * split)\n","            out = sum(outs)\n","        else:\n","            out = atten * x\n","       # out = self.se(out) * out\n","        #out = self.ca1(out) * out\n","        #out = self.sa1(out) * out\n","        return out.contiguous()\n","\n","\n","\n","\n","\n","class ResNeStBottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.275592Z","iopub.status.busy":"2024-02-11T06:21:04.275183Z","iopub.status.idle":"2024-02-11T06:21:04.334146Z","shell.execute_reply":"2024-02-11T06:21:04.333193Z","shell.execute_reply.started":"2024-02-11T06:21:04.275567Z"},"metadata":{},"trusted":true},"outputs":[],"source":["class SplAtConv1d_WithoutCA(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            channels,\n","            kernel_size,\n","            stride=1,\n","            padding=0,\n","            dilation=1,\n","            groups=1,\n","            bias=True,\n","            radix=2,\n","            reduction_factor=4,\n","            norm_layer=None,\n","            dropblock_prob=0.0,\n","            **kwargs,\n","\n","    ):\n","        super().__init__()\n","\n","        self.dropblock_prob = dropblock_prob\n","        inter_channels = max(in_channels * radix // reduction_factor, 32)\n","        self.radix = radix\n","        self.cardinality = groups\n","        self.channels = channels\n","\n","        self.conv = nn.Conv1d(\n","            in_channels,\n","            channels * radix,\n","            kernel_size,\n","            stride,\n","            padding,\n","            dilation,\n","            groups=groups * radix,\n","            bias=bias,\n","            **kwargs,\n","        )\n","        self.bn0 = norm_layer(self.channels * radix)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc1 = nn.Conv1d(self.channels, inter_channels, 1, groups=self.cardinality)\n","        self.bn1 = norm_layer(inter_channels)\n","        self.fc2 = nn.Conv1d(inter_channels, self.channels * radix, 1, groups=self.cardinality)\n","        if dropblock_prob > 0.0:\n","            self.dropblock = DropBlock1D(dropblock_prob, 3)\n","        self.rsoftmax = rSoftMax(radix, self.cardinality)\n","        self.se = SEModule(in_channels)\n","        self.ca1 = ChannelAttention1d(in_channels)\n","        self.sa1 = SpatialAttention1d()\n","\n","    def forward(self, x):\n","        #x = self.ca1(x) * x\n","        #x=  self.sa1(x) * x\n","        #x = self.se(x) * x\n","        x = self.conv(x)\n","        x = self.bn0(x)\n","        if self.dropblock_prob > 0.0:\n","            x = self.dropblock(x)\n","        x = self.relu(x)\n","\n","        batch, rchannel = x.shape[:2]\n","        if self.radix > 1:\n","            splited = torch.split(x, int(rchannel // self.radix), dim=1)\n","            gap = sum(splited)\n","        else:\n","            gap = x\n","        #se放在这个位置结果非常好\n","        #位置1，通道注意力\n","        #gap = self.ca1(gap) * gap\n","        #gap = self.sa1(gap) * gap\n","        #gap = self.se(gap) * gap\n","        gap = F.adaptive_avg_pool1d(gap, 1)\n","        gap = self.fc1(gap)\n","        gap = self.bn1(gap)\n","        gap = self.relu(gap)\n","\n","        atten = self.fc2(gap)\n","        atten = self.rsoftmax(atten).view(batch, -1, 1)\n","\n","        if self.radix > 1:\n","            attens = torch.split(atten, int(rchannel // self.radix), dim=1)\n","            outs = []\n","            for att, split in zip(attens, splited):\n","                outs.append(att * split)\n","            out = sum(outs)\n","        else:\n","            out = atten * x\n","       # out = self.se(out) * out\n","        #out = self.ca1(out) * out\n","        #out = self.sa1(out) * out\n","        return out.contiguous()\n","    \n","class ResNeStBottleneck_WithoutCA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d_WithoutCA(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","        #x=  self.sa1(x) * x\n","        out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNeStBottleneck_WithoutSA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        #out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","    \n","class ResNeStBottleneck_WithoutCASA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d_WithoutCA(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        #out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.337683Z","iopub.status.busy":"2024-02-11T06:21:04.337155Z","iopub.status.idle":"2024-02-11T06:21:04.368434Z","shell.execute_reply":"2024-02-11T06:21:04.367520Z","shell.execute_reply.started":"2024-02-11T06:21:04.337657Z"},"metadata":{},"trusted":true},"outputs":[],"source":["class ResNeSt1d(nn.Module):\n","    def __init__(\n","            self,\n","            inchannels,\n","            block,\n","            layers,\n","            radix=1,\n","            groups=1,\n","            bottleneck_width=64,\n","            num_classes=1000,\n","            dilated=False,\n","            dilation=1,\n","            deep_stem=False,\n","            stem_width=32,\n","            avg_down=False,\n","            avd=False,\n","            avd_first=False,\n","            final_drop=0.0,\n","            last_gamma=False,\n","            norm_layer=nn.BatchNorm1d,\n","            dropblock_prob=0\n","    ):\n","        super().__init__()\n","\n","        self.cardinality = groups\n","        self.bottleneck_width = bottleneck_width\n","        # ResNet-D params\n","        self.inplanes = stem_width * 2 if deep_stem else 64\n","        self.avg_down = avg_down\n","        self.last_gamma = last_gamma\n","        # ResNeSt params\n","        self.radix = radix\n","        self.avd = avd\n","        self.avd_first = avd_first\n","        \n","        \n","        act = nn.ReLU\n","\n","        if deep_stem:\n","            self.conv1 = nn.Sequential(\n","                nn.Conv1d(inchannels, stem_width, 3, 2, 1, bias=False),\n","                norm_layer(stem_width),\n","                act(inplace=True),\n","                nn.Conv1d(stem_width, stem_width, 3, 1, 1, bias=False),\n","                norm_layer(stem_width),\n","                act(inplace=True),\n","                nn.Conv1d(stem_width, self.inplanes, 3, 1, 1, bias=False),\n","            )\n","        else:\n","            self.conv1 = nn.Conv1d(inchannels, self.inplanes, 7, 2, 3, bias=False)\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = act(inplace=True)\n","        self.maxpool = nn.MaxPool1d(3, 2, 1)\n","        b = 16\n","        Blist = [b * 2, b * 4, b * 8, b * 16]\n","        self.layer1 = self._make_layer(block, Blist[0], layers[0], norm_layer=norm_layer, is_first=False)\n","        self.layer2 = self._make_layer(block, Blist[1], layers[1], stride=2, norm_layer=norm_layer)\n","        if dilated or dilation == 4:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=1, dilation=2, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            # self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=1, dilation=2, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","        elif dilation == 2:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=2, dilation=1, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            # self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=1, dilation=2, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","        else:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=2, dilation=1, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=2, dilation=1, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","\n","        self.avgpool = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.Flatten())\n","        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n","        self.fc = nn.Linear(Blist[2] * block.expansion*2, num_classes)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None, is_first=True,\n","                    dropblock_prob=0.0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            down_layers = []\n","            if self.avg_down:\n","                if dilation == 1:\n","                    down_layers.append(nn.AvgPool1d(stride, stride, ceil_mode=True, count_include_pad=False))\n","                else:\n","                    down_layers.append(nn.AvgPool1d(1, 1, ceil_mode=True, count_include_pad=False))\n","                down_layers.append(nn.Conv1d(self.inplanes, planes * block.expansion, 1, 1, 0, bias=False))\n","            else:\n","                down_layers.append(nn.Conv1d(self.inplanes, planes * block.expansion, 1, stride, 0, bias=False))\n","\n","            down_layers.append(norm_layer(planes * block.expansion))\n","            downsample = nn.Sequential(*down_layers)\n","\n","        layers = []\n","        if dilation == 1 or dilation == 2:\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    stride,\n","                    downsample=downsample,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=1,\n","                    is_first=is_first,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","        elif dilation == 4:\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    stride,\n","                    downsample=downsample,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=2,\n","                    is_first=is_first,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","        else:\n","            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n","\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=dilation,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = x.permute(0, -1, 1)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","        x = self.avgpool(x)\n","        \n","        if self.drop:\n","            x = self.drop(x)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def resnest_t(inchannels,block, **kwargs):\n","    model = ResNeSt1d(\n","        inchannels,\n","        block,\n","        [2, 2, 3, 3],\n","        radix=4,\n","        groups=4,\n","        bottleneck_width=8,\n","        deep_stem=True,\n","        #wisdm = 16, pamp2 = 32\n","        stem_width=32,\n","        avg_down=True,\n","        avd=True,\n","        avd_first=False,\n","        **kwargs,\n","    )\n","    return model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.370245Z","iopub.status.busy":"2024-02-11T06:21:04.369862Z","iopub.status.idle":"2024-02-11T06:21:04.395549Z","shell.execute_reply":"2024-02-11T06:21:04.394739Z","shell.execute_reply.started":"2024-02-11T06:21:04.370195Z"},"metadata":{},"trusted":true},"outputs":[],"source":["import copy\n","import time\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import pandas as pd\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, x_path, y_path, transform=None):\n","        self.x_data = torch.from_numpy(np.load(x_path)).float()\n","        self.y_data = np.load(y_path)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.x_data)\n","\n","    def __getitem__(self, idx):\n","        x = self.x_data[idx]\n","        y = self.y_data[idx]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        return x, y\n","#删除1\n","class LabelSmoothingCrossEntropy(nn.Module):\n","    \"\"\" NLL loss with label smoothing.\n","    \"\"\"\n","    def __init__(self, smoothing=0.1):\n","        super(LabelSmoothingCrossEntropy, self).__init__()\n","        assert smoothing < 1.0\n","        self.smoothing = smoothing\n","        self.confidence = 1. - smoothing\n","\n","    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n","        logprobs = F.log_softmax(input, dim=-1)\n","        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1).to(torch.int64))\n","        nll_loss = nll_loss.squeeze(1)\n","        smooth_loss = -logprobs.mean(dim=-1)\n","        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n","        return loss.mean()\n","class ClassBalancedLoss(nn.Module):\n","\n","    def __init__(self, num_classes, beta):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.beta = beta\n","\n","    def forward(self, inputs, targets):\n","        inputs = inputs.float()\n","        targets = targets.long()\n","        loss = F.cross_entropy(inputs, targets)\n","\n","        return self.beta * loss\n","\n","#删除2\n","class FocalLoss(nn.Module):\n","\n","    def __init__(self, alpha=0.25, gamma=2):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        inputs = inputs.float()\n","        targets = targets.long()\n","\n","        ce_loss = F.cross_entropy(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","\n","        focal_loss = ((1-pt)**self.gamma * ce_loss)\n","\n","        return focal_loss\n","#删除3\n","class MultiLoss(nn.Module):\n","    def __init__(self, num_classes, beta, weights, smoothing=0.15):\n","        super().__init__()\n","\n","        # Replace ClassBalancedLoss with LabelSmoothingLoss\n","        self.label_smoothing_loss = LabelSmoothingCrossEntropy(smoothing=0.1)\n","        self.focal_loss = FocalLoss()\n","        self.ce_loss=ClassBalancedLoss(num_classes,beta)\n","        self.weights = weights\n","\n","    def forward(self, inputs, targets):\n","        loss1 = self.weights[0] * self.label_smoothing_loss(inputs, targets)\n","        loss2 = self.weights[1] * self.focal_loss(inputs, targets)\n","        loss3 = self.weights[2] * self.ce_loss(inputs, targets)\n","        return loss1 + loss2 + loss3\n","    #删除4\n","    def update_weights(self, epoch, performance_metrics):\n","        # 根据验证准确率调整权重\n","        task1_acc = performance_metrics.get(\"task1\", 0.0)\n","        task2_acc = performance_metrics.get(\"task2\", 0.0)\n","        task3_acc = performance_metrics.get(\"task3\", 0.0)\n","\n","        # 根据验证准确率的倒数来调整权重\n","        # 准确率越高的任务将获得较小的权重，反之亦然\n","        self.weights[0] = 0.5*(1-self.weights[1])\n","        self.weights[1] = 1-(1.0 / (task1_acc + 1e-8)-1)-a\n","        self.weights[2] = 0.5*(1-self.weights[1])\n","\n","        print(f\"Epoch {epoch}: 更新权重 - 任务1: {self.weights[0]}, 任务2: {self.weights[1]},任务3: {self.weights[2]}\")\n","\n","class MultiLoss_Withoutweight(nn.Module):\n","    def __init__(self, num_classes, beta, weights, smoothing=0.15):\n","        super().__init__()\n","\n","        # Replace ClassBalancedLoss with LabelSmoothingLoss\n","        self.label_smoothing_loss = LabelSmoothingCrossEntropy(smoothing=0.1)\n","        self.focal_loss = FocalLoss()\n","        self.ce_loss=ClassBalancedLoss(num_classes,beta)\n","        self.weights = weights\n","\n","    def forward(self, inputs, targets):\n","        loss1 = self.label_smoothing_loss(inputs, targets)\n","        loss2 = self.focal_loss(inputs, targets)\n","        loss3 = self.ce_loss(inputs, targets)\n","        return loss1 + loss2 + loss3\n","\n","        \n","        \n"," #删除5       \n","def compute_validation_accuracy(model, val_dataloader, device):\n","    model.eval()\n","    corrects = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            corrects += (predicted == labels).sum().item()\n","\n","    accuracy = corrects / total\n","    return accuracy"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.397104Z","iopub.status.busy":"2024-02-11T06:21:04.396766Z","iopub.status.idle":"2024-02-11T06:21:04.423874Z","shell.execute_reply":"2024-02-11T06:21:04.422906Z","shell.execute_reply.started":"2024-02-11T06:21:04.397074Z"},"metadata":{},"trusted":true},"outputs":[],"source":["pamp2_b =128\n","wisdm_b = 512\n","\n","def train_val_data_process():\n","    # 训练数据集的路径\n","\n","\n","    train_dataset = CustomDataset(x_train_path, y_train_path)\n","\n","    # 将数据集拆分为训练集和验证集\n","    train_size = int(0.8 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","    # 定义训练集和验证集的数据加载器\n","\n","    train_dataloader = DataLoader(train_data, batch_size=pamp2_b, shuffle=True, num_workers=2)#wisdm  batch_size=256  pamp2  batch_size=128\n","    val_dataloader = DataLoader(val_data, batch_size=pamp2_b, shuffle=True, num_workers=2)#wisdm  batch_size=256  pamp2  batch_size=128\n","\n","    return train_dataloader, val_dataloader\n","\n","\n","def train_model_process(model, train_dataloader, val_dataloader, num_epochs,criterion):\n","    # 设定训练所用到的设备，有GPU用GPU没有GPU用CPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # 使用Adam优化器，学习率为0.001\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)#wisdm0.005  pamp2  0.01\n","\n","    # 将模型放入到训练设备中\n","    model = model.to(device)\n","    # 复制当前模型的参数\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    # 初始化参数\n","    # 最高准确度\n","    best_acc = 0.0\n","    # 训练集损失列表\n","    train_loss_all = []\n","    # 验证集损失列表\n","    val_loss_all = []\n","    # 训练集准确度列表\n","    train_acc_all = []\n","    # 验证集准确度列表\n","    val_acc_all = []\n","    # 当前时间\n","    since = time.time()\n","    #删除6\n","    multi_loss = MultiLoss(num_classes, beta, weights)\n","\n","\n","    for epoch in range(num_epochs):\n","        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n","        print(\"-\" * 10)\n","\n","        # 初始化参数\n","        # 训练集损失函数\n","        train_loss = 0.0\n","        # 训练集准确度\n","        train_corrects = 0\n","        # 验证集损失函数\n","        val_loss = 0.0\n","        # 验证集准确度\n","        val_corrects = 0\n","        # 训练集样本数量\n","        train_num = 0\n","        # 验证集样本数量\n","        val_num = 0\n","\n","        # 对每一个mini-batch训练和计算\n","        for step, (b_x, b_y) in enumerate(train_dataloader):\n","            # 将特征放入到训练设备中\n","            b_x = b_x.to(device)\n","            # 将标签放入到训练设备中\n","            b_y = b_y.to(device)\n","            # 设置模型为训练模式\n","            model.train()\n","\n","            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n","            output = model(b_x)\n","            # 查找每一行中最大值对应的行标\n","            pre_lab = torch.argmax(output, dim=1)\n","            # 计算每一个batch的损失函数\n","            loss = criterion(output, b_y)\n","\n","            # 将梯度初始化为0\n","            optimizer.zero_grad()\n","            # 反向传播计算\n","            loss.backward()\n","            # 根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值的作用\n","            optimizer.step()\n","            # 对损失函数进行累加\n","            train_loss += loss.item() * b_x.size(0)\n","            # 如果预测正确，则准确度train_corrects加1\n","            train_corrects += torch.sum(pre_lab == b_y.data)\n","            # 当前用于训练的样本数量\n","            train_num += b_x.size(0)\n","        for step, (b_x, b_y) in enumerate(val_dataloader):\n","            # 将特征放入到验证设备中\n","            b_x = b_x.to(device)\n","            # 将标签放入到验证设备中\n","            b_y = b_y.to(device)\n","            # 设置模型为评估模式\n","            model.eval()\n","            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n","            output = model(b_x)\n","            # 查找每一行中最大值对应的行标\n","            pre_lab = torch.argmax(output, dim=1)\n","            # 计算每一个batch的损失函数\n","            loss = criterion(output, b_y)\n","\n","            # 对损失函数进行累加\n","            val_loss += loss.item() * b_x.size(0)\n","            # 如果预测正确，则准确度train_corrects加1\n","            val_corrects += torch.sum(pre_lab == b_y.data)\n","            # 当前用于验证的样本数量\n","            val_num += b_x.size(0)\n","\n","        # 计算并保存每一次迭代的loss值和准确率\n","        # 计算并保存训练集的loss值\n","        train_loss_all.append(train_loss / train_num)\n","        # 计算并保存训练集的准确率\n","        train_acc_all.append(train_corrects.double().item() / train_num)\n","\n","        # 计算并保存验证集的loss值\n","        val_loss_all.append(val_loss / val_num)\n","        # 计算并保存验证集的准确率\n","        val_acc_all.append(val_corrects.double().item() / val_num)\n","\n","        print(\"{} train loss:{:.4f} train acc: {:.4f}\".format(epoch, train_loss_all[-1], train_acc_all[-1]))\n","        print(\"{} val loss:{:.4f} val acc: {:.4f}\".format(epoch, val_loss_all[-1], val_acc_all[-1]))\n","\n","        if val_acc_all[-1] > best_acc:\n","            # 保存当前最高准确度\n","            best_acc = val_acc_all[-1]\n","            # 保存当前最高准确度的模型参数\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        # 计算训练和验证的耗时\n","        time_use = time.time() - since\n","        print(\"训练和验证耗费的时间{:.0f}m{:.0f}s\".format(time_use // 60, time_use % 60))\n","        #删除7\n","        val_acc_task1 = compute_validation_accuracy(model, val_dataloader, device)\n","        val_acc_task2 = compute_validation_accuracy(model, val_dataloader, device)\n","        val_acc_task3 = compute_validation_accuracy(model, val_dataloader, device)\n","        multi_loss.update_weights(epoch, {\"task1\": val_acc_task1, \"task2\": val_acc_task2, \"task3\": val_acc_task3})\n","        multi_loss = MultiLoss(num_classes, beta, multi_loss.weights)\n","\n"," \n","\n","    # 选择最优参数，保存最优参数的模型\n","    print(best_acc)\n","    train_process = pd.DataFrame(data={\"epoch\": range(num_epochs),\n","                                       \"train_loss_all\": train_loss_all,\n","                                       \"val_loss_all\": val_loss_all,\n","                                       \"train_acc_all\": train_acc_all,\n","                                       \"val_acc_all\": val_acc_all, })\n","\n","    return train_process\n","\n","\n","def matplot_acc_loss(train_process):\n","    # 显示每一次迭代后的训练集和验证集的损失函数和准确率\n","    plt.figure(figsize=(12, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(train_process['epoch'], train_process.train_loss_all, \"ro-\", label=\"Train loss\")\n","    plt.plot(train_process['epoch'], train_process.val_loss_all, \"bs-\", label=\"Val loss\")\n","    plt.legend()\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.subplot(1, 2, 2)\n","    plt.plot(train_process['epoch'], train_process.train_acc_all, \"ro-\", label=\"Train acc\")\n","    plt.plot(train_process['epoch'], train_process.val_acc_all, \"bs-\", label=\"Val acc\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"acc\")\n","    plt.legend()\n","    plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.425257Z","iopub.status.busy":"2024-02-11T06:21:04.424958Z","iopub.status.idle":"2024-02-11T06:23:31.743996Z","shell.execute_reply":"2024-02-11T06:23:31.742485Z","shell.execute_reply.started":"2024-02-11T06:21:04.425206Z"},"metadata":{},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/49\n","----------\n","0 train loss:2.1919 train acc: 0.3284\n","0 val loss:1.4850 val acc: 0.4281\n","训练和验证耗费的时间0m5s\n","Epoch 0: 更新权重 - 任务1: 0.25, 任务2: -0.7857902812311719,任务3: 0.892895140615586\n","Epoch 1/49\n","----------\n","1 train loss:1.1319 train acc: 0.4301\n","1 val loss:1.0758 val acc: 0.4996\n","训练和验证耗费的时间0m10s\n","Epoch 1: 更新权重 - 任务1: 0.892895140615586, 任务2: -0.4514034687157705,任务3: 0.7257017343578852\n","Epoch 2/49\n","----------\n","2 train loss:2.2894 train acc: 0.4859\n","2 val loss:2.2365 val acc: 0.5161\n","训练和验证耗费的时间0m16s\n","Epoch 2: 更新权重 - 任务1: 0.7257017343578852, 任务2: -0.38749996246093815,任务3: 0.693749981230469\n","Epoch 3/49\n","----------\n","3 train loss:1.6191 train acc: 0.5907\n","3 val loss:1.4311 val acc: 0.6497\n","训练和验证耗费的时间0m22s\n","Epoch 3: 更新权重 - 任务1: 0.693749981230469, 任务2: 0.010874281649145112,任务3: 0.4945628591754274\n","Epoch 4/49\n","----------\n","4 train loss:1.3345 train acc: 0.6699\n","4 val loss:1.4013 val acc: 0.7013\n","训练和验证耗费的时间0m27s\n","Epoch 4: 更新权重 - 任务1: 0.4945628591754274, 任务2: 0.12400002033475971,任务3: 0.4379999898326201\n","Epoch 5/49\n","----------\n","5 train loss:1.0039 train acc: 0.6914\n","5 val loss:0.9178 val acc: 0.7461\n","训练和验证耗费的时间0m33s\n","Epoch 5: 更新权重 - 任务1: 0.4379999898326201, 任务2: 0.20977445405227096,任务3: 0.3951127729738645\n","Epoch 6/49\n","----------\n","6 train loss:0.8676 train acc: 0.7258\n","6 val loss:0.7118 val acc: 0.7847\n","训练和验证耗费的时间0m38s\n","Epoch 6: 更新权重 - 任务1: 0.3951127729738645, 任务2: 0.27564791615036704,任务3: 0.36217604192481645\n","Epoch 7/49\n","----------\n","7 train loss:0.6564 train acc: 0.7884\n","7 val loss:0.6417 val acc: 0.7980\n","训练和验证耗费的时间0m43s\n","Epoch 7: 更新权重 - 任务1: 0.36217604192481645, 任务2: 0.29692444452447936,任务3: 0.3515377777377603\n","Epoch 8/49\n","----------\n","8 train loss:0.9639 train acc: 0.6827\n","8 val loss:0.8190 val acc: 0.6739\n","训练和验证耗费的时间0m49s\n","Epoch 8: 更新权重 - 任务1: 0.3515377777377603, 任务2: 0.06612905427679466,任务3: 0.46693547286160264\n","Epoch 9/49\n","----------\n","9 train loss:0.6667 train acc: 0.7793\n","9 val loss:0.6970 val acc: 0.7658\n","训练和验证耗费的时间0m54s\n","Epoch 9: 更新权重 - 任务1: 0.46693547286160264, 任务2: 0.24413921119191845,任务3: 0.37793039440404075\n","Epoch 10/49\n","----------\n","10 train loss:0.6995 train acc: 0.8133\n","10 val loss:0.6884 val acc: 0.8180\n","训练和验证耗费的时间1m0s\n","Epoch 10: 更新权重 - 任务1: 0.37793039440404075, 任务2: 0.3275396634653102,任务3: 0.33623016826734486\n","Epoch 11/49\n","----------\n","11 train loss:0.5729 train acc: 0.8196\n","11 val loss:0.5950 val acc: 0.8208\n","训练和验证耗费的时间1m6s\n","Epoch 11: 更新权重 - 任务1: 0.33623016826734486, 任务2: 0.3317172297075714,任务3: 0.3341413851462143\n","Epoch 12/49\n","----------\n","12 train loss:0.4778 train acc: 0.8507\n","12 val loss:0.5427 val acc: 0.8226\n","训练和验证耗费的时间1m11s\n","Epoch 12: 更新权重 - 任务1: 0.3341413851462143, 任务2: 0.33431374026912714,任务3: 0.3328431298654364\n","Epoch 13/49\n","----------\n","13 train loss:0.5751 train acc: 0.8018\n","13 val loss:0.4798 val acc: 0.8576\n","训练和验证耗费的时间1m17s\n","Epoch 13: 更新权重 - 任务1: 0.3328431298654364, 任务2: 0.3840147315020032,任务3: 0.30799263424899836\n","Epoch 14/49\n","----------\n","14 train loss:0.4679 train acc: 0.8589\n","14 val loss:0.4976 val acc: 0.8377\n","训练和验证耗费的时间1m22s\n","Epoch 14: 更新权重 - 任务1: 0.30799263424899836, 任务2: 0.3561950749465536,任务3: 0.32190246252672317\n","Epoch 15/49\n","----------\n","15 train loss:0.4461 train acc: 0.8610\n","15 val loss:0.5148 val acc: 0.8457\n","训练和验证耗费的时间1m28s\n","Epoch 15: 更新权重 - 任务1: 0.32190246252672317, 任务2: 0.36757878678385286,任务3: 0.31621060660807354\n","Epoch 16/49\n","----------\n","16 train loss:0.4343 train acc: 0.8750\n","16 val loss:0.4285 val acc: 0.8734\n","训练和验证耗费的时间1m33s\n","Epoch 16: 更新权重 - 任务1: 0.31621060660807354, 任务2: 0.4050782949229896,任务3: 0.2974608525385052\n","Epoch 17/49\n","----------\n","17 train loss:0.4275 train acc: 0.8702\n","17 val loss:0.4188 val acc: 0.8783\n","训练和验证耗费的时间1m39s\n","Epoch 17: 更新权重 - 任务1: 0.2974608525385052, 任务2: 0.4114770588705287,任务3: 0.2942614705647356\n","Epoch 18/49\n","----------\n","18 train loss:0.3588 train acc: 0.8997\n","18 val loss:0.3489 val acc: 0.9106\n","训练和验证耗费的时间1m44s\n","Epoch 18: 更新权重 - 任务1: 0.2942614705647356, 任务2: 0.4518097925761974,任务3: 0.27409510371190127\n","Epoch 19/49\n","----------\n","19 train loss:0.3461 train acc: 0.9028\n","19 val loss:0.3374 val acc: 0.9092\n","训练和验证耗费的时间1m50s\n","Epoch 19: 更新权重 - 任务1: 0.27409510371190127, 任务2: 0.4501157082023525,任务3: 0.2749421458988237\n","Epoch 20/49\n","----------\n","20 train loss:0.3098 train acc: 0.9150\n","20 val loss:0.3615 val acc: 0.8871\n","训练和验证耗费的时间1m55s\n","Epoch 20: 更新权重 - 任务1: 0.2749421458988237, 任务2: 0.42272728543471055,任务3: 0.2886363572826447\n","Epoch 21/49\n","----------\n","21 train loss:0.3543 train acc: 0.8946\n","21 val loss:0.3638 val acc: 0.8832\n","训练和验证耗费的时间2m1s\n","Epoch 21: 更新权重 - 任务1: 0.2886363572826447, 任务2: 0.41780469721723307,任务3: 0.29109765139138344\n","Epoch 22/49\n","----------\n","22 train loss:0.3470 train acc: 0.9043\n","22 val loss:0.3704 val acc: 0.8997\n","训练和验证耗费的时间2m6s\n","Epoch 22: 更新权重 - 任务1: 0.29109765139138344, 任务2: 0.4385424909192394,任务3: 0.28072875454038027\n","Epoch 23/49\n","----------\n","23 train loss:0.3906 train acc: 0.8825\n","23 val loss:0.3772 val acc: 0.8871\n","训练和验证耗费的时间2m12s\n","Epoch 23: 更新权重 - 任务1: 0.28072875454038027, 任务2: 0.42272728543471055,任务3: 0.2886363572826447\n","Epoch 24/49\n","----------\n","24 train loss:0.3537 train acc: 0.9036\n","24 val loss:0.3559 val acc: 0.9008\n","训练和验证耗费的时间2m17s\n","Epoch 24: 更新权重 - 任务1: 0.2886363572826447, 任务2: 0.4398404171513241,任务3: 0.2800797914243379\n","Epoch 25/49\n","----------\n","25 train loss:0.3342 train acc: 0.9127\n","25 val loss:0.3539 val acc: 0.9095\n","训练和验证耗费的时间2m23s\n","Epoch 25: 更新权重 - 任务1: 0.2800797914243379, 任务2: 0.4505397191043205,任务3: 0.2747301404478397\n","Epoch 26/49\n","----------\n","26 train loss:0.3066 train acc: 0.9249\n","26 val loss:0.3113 val acc: 0.9201\n","训练和验证耗费的时间2m29s\n","Epoch 26: 更新权重 - 任务1: 0.2747301404478397, 任务2: 0.46310976791086483,任务3: 0.26844511604456756\n","Epoch 27/49\n","----------\n","27 train loss:0.3381 train acc: 0.9053\n","27 val loss:0.3200 val acc: 0.9123\n","训练和验证耗费的时间2m34s\n","Epoch 27: 更新权重 - 任务1: 0.26844511604456756, 任务2: 0.45392007350507296,任务3: 0.2730399632474635\n","Epoch 28/49\n","----------\n","28 train loss:0.3151 train acc: 0.9117\n","28 val loss:0.2918 val acc: 0.9278\n","训练和验证耗费的时间2m40s\n","Epoch 28: 更新权重 - 任务1: 0.2730399632474635, 任务2: 0.4721466480500293,任务3: 0.2639266759749853\n","Epoch 29/49\n","----------\n","29 train loss:0.2824 train acc: 0.9324\n","29 val loss:0.3297 val acc: 0.9130\n","训练和验证耗费的时间2m45s\n","Epoch 29: 更新权重 - 任务1: 0.2639266759749853, 任务2: 0.4547619167573695,任务3: 0.27261904162131523\n","Epoch 30/49\n","----------\n","30 train loss:0.3159 train acc: 0.9124\n","30 val loss:0.3095 val acc: 0.9183\n","训练和验证耗费的时间2m51s\n","Epoch 30: 更新权重 - 任务1: 0.27261904162131523, 任务2: 0.46103475794474574,任务3: 0.2694826210276271\n","Epoch 31/49\n","----------\n","31 train loss:0.3065 train acc: 0.9214\n","31 val loss:0.2828 val acc: 0.9323\n","训练和验证耗费的时间2m56s\n","Epoch 31: 更新权重 - 任务1: 0.2694826210276271, 任务2: 0.47741633342989326,任务3: 0.26129183328505334\n","Epoch 32/49\n","----------\n","32 train loss:0.2653 train acc: 0.9403\n","32 val loss:0.3080 val acc: 0.9116\n","训练和验证耗费的时间3m2s\n","Epoch 32: 更新权重 - 任务1: 0.26129183328505334, 任务2: 0.4530769351093255,任务3: 0.2734615324453372\n","Epoch 33/49\n","----------\n","33 train loss:0.2651 train acc: 0.9381\n","33 val loss:0.2677 val acc: 0.9407\n","训练和验证耗费的时间3m7s\n","Epoch 33: 更新权重 - 任务1: 0.2734615324453372, 任务2: 0.4870108200955838,任务3: 0.2564945899522081\n","Epoch 34/49\n","----------\n","34 train loss:0.2458 train acc: 0.9553\n","34 val loss:0.2781 val acc: 0.9299\n","训练和验证耗费的时间3m13s\n","Epoch 34: 更新权重 - 任务1: 0.2564945899522081, 任务2: 0.47458523026803506,任务3: 0.26270738486598244\n","Epoch 35/49\n","----------\n","35 train loss:0.2292 train acc: 0.9583\n","35 val loss:0.2640 val acc: 0.9362\n","训练和验证耗费的时间3m18s\n","Epoch 35: 更新权重 - 任务1: 0.26270738486598244, 任务2: 0.4818352174022695,任务3: 0.25908239129886523\n","Epoch 36/49\n","----------\n","36 train loss:0.2485 train acc: 0.9490\n","36 val loss:0.2693 val acc: 0.9369\n","训练和验证耗费的时间3m24s\n","Epoch 36: 更新权重 - 任务1: 0.25908239129886523, 任务2: 0.4826347419316083,任务3: 0.2586826290341958\n","Epoch 37/49\n","----------\n","37 train loss:0.2400 train acc: 0.9504\n","37 val loss:0.2647 val acc: 0.9393\n","训练和验证耗费的时间3m29s\n","Epoch 37: 更新权重 - 任务1: 0.2586826290341958, 任务2: 0.48542367688007343,任务3: 0.25728816155996326\n","Epoch 38/49\n","----------\n","38 train loss:0.2421 train acc: 0.9511\n","38 val loss:0.2851 val acc: 0.9225\n","训练和验证耗费的时间3m34s\n","Epoch 38: 更新权重 - 任务1: 0.25728816155996326, 任务2: 0.46600153208500056,任务3: 0.2669992339574997\n","Epoch 39/49\n","----------\n","39 train loss:0.3194 train acc: 0.9116\n","39 val loss:0.4824 val acc: 0.9127\n","训练和验证耗费的时间3m39s\n","Epoch 39: 更新权重 - 任务1: 0.2669992339574997, 任务2: 0.4543411568375683,任务3: 0.2728294215812158\n","Epoch 40/49\n","----------\n","40 train loss:0.2794 train acc: 0.9373\n","40 val loss:0.3460 val acc: 0.9011\n","训练和验证耗费的时间3m44s\n","Epoch 40: 更新权重 - 任务1: 0.2728294215812158, 任务2: 0.44027238585581013,任务3: 0.2798638070720949\n","Epoch 41/49\n","----------\n","41 train loss:0.2694 train acc: 0.9412\n","41 val loss:0.2875 val acc: 0.9299\n","训练和验证耗费的时间3m50s\n","Epoch 41: 更新权重 - 任务1: 0.2798638070720949, 任务2: 0.47458523026803506,任务3: 0.26270738486598244\n","Epoch 42/49\n","----------\n","42 train loss:0.2455 train acc: 0.9602\n","42 val loss:0.3057 val acc: 0.9215\n","训练和验证耗费的时间3m55s\n","Epoch 42: 更新权重 - 任务1: 0.26270738486598244, 任务2: 0.46476409092501075,任务3: 0.2676179545374946\n","Epoch 43/49\n","----------\n","43 train loss:0.2984 train acc: 0.9225\n","43 val loss:0.2738 val acc: 0.9358\n","训练和验证耗费的时间4m0s\n","Epoch 43: 更新权重 - 任务1: 0.2676179545374946, 任务2: 0.48143500579822923,任务3: 0.25928249710088536\n","Epoch 44/49\n","----------\n","44 train loss:0.2427 train acc: 0.9534\n","44 val loss:0.2849 val acc: 0.9288\n","训练和验证耗费的时间4m6s\n","Epoch 44: 更新权重 - 任务1: 0.25928249710088536, 任务2: 0.47336732000965037,任务3: 0.2633163399951748\n","Epoch 45/49\n","----------\n","45 train loss:0.2360 train acc: 0.9559\n","45 val loss:0.2694 val acc: 0.9376\n","训练和验证耗费的时间4m11s\n","Epoch 45: 更新权重 - 任务1: 0.2633163399951748, 任务2: 0.4834330704631597,任务3: 0.2582834647684201\n","Epoch 46/49\n","----------\n","46 train loss:0.3413 train acc: 0.8994\n","46 val loss:0.3313 val acc: 0.9018\n","训练和验证耗费的时间4m17s\n","Epoch 46: 更新权重 - 任务1: 0.2582834647684201, 任务2: 0.44113531556174984,任务3: 0.27943234221912505\n","Epoch 47/49\n","----------\n","47 train loss:0.2925 train acc: 0.9220\n","47 val loss:0.2822 val acc: 0.9264\n","训练和验证耗费的时间4m22s\n","Epoch 47: 更新权重 - 任务1: 0.27943234221912505, 任务2: 0.47051477319716833,任务3: 0.2647426134014158\n","Epoch 48/49\n","----------\n","48 train loss:0.2585 train acc: 0.9533\n","48 val loss:0.6946 val acc: 0.9092\n","训练和验证耗费的时间4m28s\n","Epoch 48: 更新权重 - 任务1: 0.2647426134014158, 任务2: 0.4501157082023525,任务3: 0.2749421458988237\n","Epoch 49/49\n","----------\n","49 train loss:0.2853 train acc: 0.9408\n","49 val loss:0.2815 val acc: 0.9372\n","训练和验证耗费的时间4m33s\n","Epoch 49: 更新权重 - 任务1: 0.2749421458988237, 任务2: 0.48303405552931883,任务3: 0.25848297223534056\n","0.9407433380084151\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1200x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# search pamp to find the differences and change\n","num_classes = 17 #pamp2 =12 wisdm =6\n","inchannels = 113 #pamp2 =36 wisdm =3\n","\n","#1\n","#model_n_casa = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutCASA)\n","#2\n","#model_n_ca = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutCA)\n","#3\n","#model_n_sa = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutSA)\n","#4\n","model = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck)\n","\n","model = model\n","if __name__ == '__main__':\n","    # 加载需要的模型\n","    \n","    # 加载数据集\n","    train_data, val_data = train_val_data_process()\n","    # 利用现有的模型进行模型的训练\n","      # 替换为你的类别总数\n","    beta = 1  # 平衡系数  #wisdm\n","    #beta=0.8  #pamp2\n","    #weights = [0.1, 0.8,0.1] #wisdm\n","    a=0.45\n","    weights = [0.25, 0.5,0.25] #pamp2\n","    #4\n","    criterion1 = nn.CrossEntropyLoss()\n","    #5\n","    criterion2 = MultiLoss_Withoutweight(num_classes, beta, weights)\n","    #不测\n","    criterion3 = MultiLoss(num_classes, beta, weights,smoothing=0.1)#smoothing=0.15  #pamp2\n","\n","    train_process = train_model_process(model, train_data,val_data, num_epochs=50,criterion = criterion3)\n","    matplot_acc_loss(train_process)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model, 'res_oppo_model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-11T06:23:31.745275Z","iopub.status.idle":"2024-02-11T06:23:31.745648Z","shell.execute_reply":"2024-02-11T06:23:31.745490Z","shell.execute_reply.started":"2024-02-11T06:23:31.745473Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.4076, Test Acc: 89.90%, G-mean: 0.9835\n","              precision    recall  f1-score   support\n","\n","           0     0.8750    1.0000    0.9333        91\n","           1     0.9250    0.7115    0.8043       104\n","           2     0.9189    0.8000    0.8553        85\n","           3     1.0000    0.9677    0.9836       124\n","           4     1.0000    0.9158    0.9560        95\n","           5     0.8614    0.9158    0.8878        95\n","           6     0.9528    0.9902    0.9712       102\n","           7     0.8500    0.9273    0.8870        55\n","           8     0.9744    0.7917    0.8736        48\n","           9     0.8172    0.8085    0.8128        94\n","          10     0.8092    0.9609    0.8786       128\n","          11     0.8235    0.9655    0.8889        29\n","\n","    accuracy                         0.8990      1050\n","   macro avg     0.9006    0.8962    0.8944      1050\n","weighted avg     0.9045    0.8990    0.8979      1050\n","\n","G-mean: 0.9835\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","import torch.nn as nn\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, x_path, y_path, transform=None):\n","        self.x_data = np.load(x_path)\n","        self.y_data = np.load(y_path)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.x_data)\n","\n","    def __getitem__(self, idx):\n","        x = self.x_data[idx]\n","        y = self.y_data[idx]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        return x, y\n","\n","def test_final(model, test_dataloader):\n","    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","    model = model.to(device)\n","    criterion1 = nn.CrossEntropyLoss()\n","    num_classes = 6\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)  \n","\n","    model.eval()\n","    test_loss = 0.0\n","    test_correct = 0\n","    test_total = 0\n","    y_true = []\n","    y_pred = []\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(test_dataloader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion1(outputs, labels)\n","            _, predicted = torch.max(outputs.data, 1)\n","            test_correct += (predicted == labels).sum().item()\n","            test_total += labels.size(0)\n","            test_loss += loss.item()\n","            y_true.extend(labels.tolist())\n","            y_pred.extend(predicted.tolist())\n","            conf_matrix += confusion_matrix(labels.cpu(), predicted.cpu(), labels=range(num_classes))\n","\n","    report = classification_report(y_true, y_pred,digits=4)\n","    test_acc = 100.0 * test_correct / test_total\n","    test_loss = test_loss / len(test_dataloader)\n","\n","    g_mean = np.sqrt(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n","    g_mean = np.mean(g_mean)\n","    report += '\\nG-mean: {:.4f}'.format(g_mean)\n","    print('Test Loss: {:.4f}, Test Acc: {:.2f}%, G-mean: {:.4f}'.format(test_loss, test_acc, g_mean))\n","    print(report)\n","\n","\n","def test_data_process():\n","    test_data = CustomDataset(x_test_path, y_test_path)\n","    test_dataloader = DataLoader(test_data, batch_size=pamp2_b, shuffle=True, num_workers=2)\n","    return test_dataloader\n","\n","\n","def test_model_process(model, test_dataloader):\n","    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","    model = model.to(device)\n","    classes = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n","\n","    test_corrects = 0.0\n","    test_num = 0\n","\n","    with torch.no_grad():\n","        for test_data_x, test_data_y in test_dataloader:\n","            test_data_x = test_data_x.to(device)\n","            test_data_y = test_data_y.to(device)\n","            model.eval()\n","            output = model(test_data_x)\n","            pre_lab = torch.argmax(output, dim=1)\n","            test_corrects += torch.sum(pre_lab == test_data_y.data)\n","            test_num += test_data_x.size(0)\n","\n","    test_acc = test_corrects.double().item() / test_num\n","    print(\"测试的准确率为：\", test_acc)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    model = torch.load('res_pamap2_model.pt')\n","    test_dataloader = test_data_process()\n","    test_final(model, test_dataloader)\n","  \n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4183646,"sourceId":7226790,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
