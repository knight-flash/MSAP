{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:04.350947Z","iopub.status.busy":"2024-03-18T13:56:04.350544Z","iopub.status.idle":"2024-03-18T13:56:07.024124Z","shell.execute_reply":"2024-03-18T13:56:07.023257Z","shell.execute_reply.started":"2024-03-18T13:56:04.350897Z"},"trusted":true},"outputs":[],"source":["train_x_list = \"/root/HAR/dataset/PAMAP2/x_train.npy\"\n","train_y_list = \"/root/HAR/dataset/PAMAP2/y_train.npy\"\n","test_x_list = \"/root/HAR/dataset/PAMAP2/x_test.npy\"\n","test_y_list = \"/root/HAR/dataset/PAMAP2/y_test.npy\"\n","import datetime\n","import os\n","import csv\n","import numpy as np\n","import random\n","import shutil\n","import torch\n","import argparse\n","from torch.cuda.amp import autocast as autocast\n","from torch.cuda.amp import GradScaler\n","import os\n","\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","import torch.utils.data as Data\n","from collections import Counter\n","from imblearn.over_sampling import BorderlineSMOTE\n","\n","from sklearn.model_selection import train_test_split\n","\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","\n","import torch\n","\n","parser = argparse.ArgumentParser(description=\"Experiment Info and Setings, Model Hyperparameters\")\n","parser.add_argument(\"--lambda_cls\", type=float, default=1)\n","parser.add_argument(\"--lambda_sc\", type=float, default=2)\n","parser.add_argument(\"--lambda_st\", type=float, default=0.2)\n","parser.add_argument(\"--lambda_cos_loss\", type=float, default=2)\n","# Experiment Info\n","parser.add_argument(\"--experiment_date\", type=str, default=f\"{datetime.datetime.now().strftime('%Y%m%d')}\")\n","parser.add_argument(\"--experiment_time\", type=str, default=f\"{datetime.datetime.now().strftime('%H:%M:%S')}\")\n","parser.add_argument(\"--characteristic\", '-c', type=str, default=\"\")\n","parser.add_argument(\"--data\", type=str, default='Sleep-edf')\n","parser.add_argument(\"--data_type\", type=str, default='epoch')\n","parser.add_argument(\"--scheme\", type=str, default='M_M')\n","parser.add_argument(\"--loss_weight\", type=int, default=1)\n","parser.add_argument(\"--lstm_layers\", type=int, default=1)\n","parser.add_argument(\"--cos_loss\", type=int, default=1)\n","parser.add_argument(\"--mha\", type=int, default=1)\n","parser.add_argument(\"--mha_length\", type=int, default=8)\n","parser.add_argument(\"--mha_head\", type=int, default=2)\n","parser.add_argument(\"--mass_ch\", type=str, default='eeg_f4-ler')\n","parser.add_argument(\"--downsample\", type=int, default=100)\n","# Experiment Hyperparameters\n","parser.add_argument(\"--epoch\", type=int, default=150)\n","parser.add_argument(\"--lr\", type=float, default=1e-3)\n","parser.add_argument(\"--wd\", type=float, default=1e-3)\n","parser.add_argument(\"--batch\", type=int, default=128)\n","parser.add_argument(\"--early_stop\", type=int, default=50)\n","parser.add_argument(\"--dropout\", type=int, default=0.5)\n","parser.add_argument(\"--scheduler\", type=int, default=0)\n","parser.add_argument(\"--stride\", type=str, default=2)\n","parser.add_argument(\"--preprocess\", type=str, default='robustscale')\n","# Model Hyperparameters\n","parser.add_argument(\"--seq_length\", type=int, default=4)\n","# GPU\n","parser.add_argument(\"--GPU\", type=bool, default=True)\n","parser.add_argument(\"--gpu_idx\", type=int, default=-1)\n","# Experiment Sbj\n","parser.add_argument(\"--range_start\", type=int, default=0)\n","parser.add_argument(\"--range_end\", type=int, default=31)\n","args = parser.parse_args(args=[])\n","#args = parser.parse_known_args()[0]\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, lr_scheduler\n","from torch import default_generator  # type: ignore\n","from typing import Tuple\n","from torch import Tensor, Generator\n","import mne\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader, TensorDataset, Dataset\n","from numpy.random import shuffle\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:07.026253Z","iopub.status.busy":"2024-03-18T13:56:07.025849Z","iopub.status.idle":"2024-03-18T13:56:07.107554Z","shell.execute_reply":"2024-03-18T13:56:07.106609Z","shell.execute_reply.started":"2024-03-18T13:56:07.026225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["使用GPU训练中：NVIDIA GeForce RTX 4090\n"]}],"source":["def record_name(cv_i):\n","    # return args.characteristic + '_Finetuning_Model_' + args.finetuning_model_name + str(args.lr_finetune_network)\n","    return args.characteristic + '_CV_' + str(cv_i)\n","\n","\n","def writelog(file, line):\n","    with open(file, 'a', encoding='utf-8') as f:\n","        f.write(line + '\\n')\n","    print(line + '\\n')\n","\n","def label_stage_transition(label_list):\n","    for l in range(len(label_list)):\n","        label_shape = label_list[l].shape\n","        label = label_list[l].flatten()\n","        lbl = np.zeros_like(label)\n","        for i in range(1, len(label)):\n","            if i != len(label) - 1:\n","                if label[i] == label[i - 1] and label[i] == label[i + 1]:\n","                    lbl[i] = 0\n","                else:\n","                    lbl[i] = 1\n","            else:\n","                if label[i] == label[i - 1]:\n","                    lbl[i] = 0\n","                else:\n","                    lbl[i] = 1\n","        #cls, count = np.unique(lbl, return_counts=True)\n","        #writelog(log_file, f'Lable Count: {dict(zip(cls, count))}')\n","        lbl = lbl.reshape(label_shape)\n","        label_list[l] = lbl\n","    return label_list\n","\n","def float_tensor(x):\n","    return torch.FloatTensor(x)\n","\n","def long_tensor(x):\n","    return torch.LongTensor(x)\n","\n","def dcn(x):  # detach, cpu, numpy\n","    if type(x) == np.ndarray:\n","        return x\n","    else:\n","        return x.detach().cpu().numpy()\n","\n","def pb_argmax(x):\n","    if len(x.shape) == 1:\n","        return (x)\n","    else:\n","        return np.argmax(x, axis=-1)\n","\n","def flatten_1dim(x):\n","    if len(x.shape) == 1:\n","        return (x)\n","    else:\n","        return x.flatten()\n","\n","def flatten_logit_list(l):\n","    for i in range(len(l)):\n","        l[i] = l[i].flatten(end_dim=1)\n","    return l\n","\n","def standardize(x):\n","    return (x - x.mean(axis=1)[:, None]) / x.std(axis=1)[:, None]\n","\n","def downsample_to_100(x):\n","    x = mne.filter.resample(x, down=2.56, axis=-1)\n","    return x\n","\n","def tr_val_split(idx_tr, idx_val, X_tr_val, Y_tr_val):\n","    return X_tr_val[idx_tr], Y_tr_val[idx_tr], X_tr_val[idx_val], Y_tr_val[idx_val]\n","\n","def pytorch_sliding_window(x, window_size, step_size=1):\n","    # Unfold Dimension to Make Slding Window\n","    return x.unfold(0, window_size, step_size)\n","\n","''' Count Parameters '''\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","''' Loss '''\n","\n","def loss_cross_entropy(weight=None, reduction='mean'):  # Take Logit as an Input\n","    return nn.CrossEntropyLoss(weight=weight, reduction=reduction)\n","\n","def loss_cos_loss(margin=0, reduction='mean'):\n","    return nn.CosineEmbeddingLoss(margin=margin, reduction=reduction)\n","\n","def loss_mse(reduction='none'):\n","    return torch.nn.MSELoss(reduction=reduction)\n","\n","def loss_calculate(y_hat, y, y_pre=None, loss_type=None, ignore_index=None, regularizer_const=None, step=None):\n","    loss = loss_type(y_hat, y)\n","    return loss\n","\n","def loss_weight_balance(label):\n","    '''\n","    Qu et al., (JBHI, 2020)\n","    '''\n","    label, count = np.unique(label, return_counts=True)\n","    ratio_reciprocal = np.reciprocal(count / count.sum())\n","    loss_weight = ratio_reciprocal * (len(label) / (ratio_reciprocal.sum()))  # Weight Sum = Num of Label\n","    return loss_weight\n","\n","\n","''' Optimizer '''\n","\n","def optimizer(params, name='network'):\n","    if name == 'network':\n","        lr = args.lr_network\n","    elif name == 'rss':\n","        lr = args.lr_rss\n","    opt = Adam(params, lr=lr)\n","    # lr_scedule = lr_scheduler.ExponentialLR(opt, gamma=0.96)\n","    return opt\n","\n","\n","class Optimizer():\n","    def __init__(self, network):\n","        super(Optimizer, self).__init__()\n","        self.opt = torch.optim.Adam(network.parameters(),\n","                                    lr=args.lr, weight_decay=args.wd)\n","\n","    def opt_zero_grad(self):\n","        self.opt.zero_grad()\n","\n","    def opt_step(self):\n","        self.opt.step()\n","\n","def tensor_form(X: list, Y: list):\n","    for i in range(len(X)):\n","        X[i] = float_tensor(X[i])\n","    for i in range(len(Y)):\n","        Y[i] = long_tensor((Y[i]))\n","    return X, Y\n","\n","class tensordataset_w_indices(Dataset[Tuple[Tensor, ...]]):\n","    r\"\"\" *** Custom ***\n","    Dataset wrapping tensors.\n","    Each sample will be retrieved by indexing tensors along the first dimension.\n","    Args:\n","        *tensors (Tensor): tensors that have the same size of the first dimension.\n","    \"\"\"\n","    tensors: Tuple[Tensor, ...]\n","\n","    def __init__(self, *tensors: Tensor) -> None:\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors), \"Size mismatch between tensors\"\n","        self.tensors = tensors\n","\n","    def __getitem__(self, index):\n","        # (X, Y), idx\n","        return tuple(tensor[index] for tensor in self.tensors), index\n","\n","    def __len__(self):\n","        return self.tensors[0].size(0)\n","\n","def dataloader_form(X_tr, Y_tr, X_val, Y_val, X_ts, Y_ts):\n","    tr_loader = DataLoader(tensordataset_w_indices(X_tr, Y_tr), batch_size=args.batch, shuffle=True, pin_memory=True)\n","    val_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=args.batch, pin_memory=True)\n","    ts_loader = DataLoader(TensorDataset(X_ts, Y_ts), batch_size=args.batch, pin_memory=True)\n","    return tr_loader, val_loader, ts_loader\n","\n","def predict(dataloader, network):\n","    Y_new, Y_hat, Y_hat_pb = np.array([]), np.array([]), np.array([[], [], [], [], [], []]).reshape(0, 12)\n","    v_t_correct = 0\n","    v_t_total = 0\n","    test_loss = 0.0\n","    test_correct = 0\n","    test_total = 0\n","    y_true = []\n","    y_pred = []\n","    for iteration, batch in enumerate(zip(dataloader)):\n","        x, y = batch[0]\n","        x, y = x.to(device), y.flatten().to(device)\n","\n","        with torch.no_grad():\n","            l_1, l_2, l_2_t = network(x)\n","            loss = l_2\n","            _, predicted = torch.max(x.data, 1)\n","            test_correct += (predicted == y).sum().item()\n","            test_total += y.size(0)\n","            # 累计测试损失.\n","            test_loss += loss.item()\n","\n","    # 计算测试准确率和损失.\n","    test_acc = 100.0 * test_correct / test_total\n","    test_loss = test_loss / len(dataloader)\n","\n","    # 打印测试结果.\n","    print('Test Loss: {:.4f}, Test Acc: {:.2f}%'.format(test_loss, test_acc))\n","    # 返回测试结果.\n","    return test_loss, test_acc\n","\n","if (torch.cuda.is_available()):\n","    device = torch.device(\"cuda\")\n","    print(\"使用GPU训练中：{}\".format(torch.cuda.get_device_name()))\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"使用CPU训练\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:07.109210Z","iopub.status.busy":"2024-03-18T13:56:07.108833Z","iopub.status.idle":"2024-03-18T13:56:07.125104Z","shell.execute_reply":"2024-03-18T13:56:07.124105Z","shell.execute_reply.started":"2024-03-18T13:56:07.109172Z"},"trusted":true},"outputs":[],"source":["class HAR_BorderlineSMOTE(Data.Dataset):\n","    def __init__(self, filename_x, filename_y):\n","        self.filename_x = filename_x\n","        self.filename_y = filename_y\n","\n","    def HAR_data(self):\n","        data_x_raw = np.load(self.filename_x)\n","        data_x = data_x_raw\n","        data_y = np.load(self.filename_y)\n","        data_x = torch.tensor(data_x, dtype=torch.float32)\n","        data_y = torch.tensor(data_y, dtype=torch.long)\n","        smo = BorderlineSMOTE(random_state=42, kind=\"borderline-1\")\n","        n, nx, ny = data_x.shape\n","        data_x = data_x.reshape((n, nx * ny))\n","        data_x, data_y = smo.fit_resample(data_x, data_y)\n","        data_x = data_x.reshape((data_x.shape[0], nx, ny))\n","\n","        print(Counter(data_y))\n","        train_data, val_data, train_label, val_label = train_test_split(data_x, data_y, test_size=0.1, random_state=42)\n","\n","        torch_dataset = []\n","        torch_dataset = Data.TensorDataset(torch.from_numpy(train_data),\n","                                           torch.from_numpy(train_label)), Data.TensorDataset(\n","            torch.from_numpy(val_data), torch.from_numpy(val_label))\n","        return torch_dataset\n","\n","class trian_HAR(Data.Dataset):\n","    def __init__(self, filename_x, filename_y):\n","        self.filename_x = filename_x\n","        self.filename_y = filename_y\n","\n","    def HAR_data(self):\n","        data_x_raw = np.load(self.filename_x)\n","\n","        data_x = data_x_raw  # (N, C, H, W) (7352, 1, 128, 9)\n","        # data_x = np.expand_dims(data_x_raw, 1)\n","        data_y = np.load(self.filename_y)\n","\n","        data_x = data_x.transpose(0, 2, 1)\n","        print(\"data_x.shape:\", data_x.shape)\n","        data_x = X_window_maker(data_x)\n","        data_y = Y_window_maker(data_y)\n","        print(\"data_x.shape:\", data_x.shape)\n","        print(\"data_y.shape:\", data_y.shape)\n","        data_x = torch.tensor(data_x, dtype=torch.float32)\n","        data_y = torch.tensor(data_y, dtype=torch.long)\n","        train_data, val_data, train_label, val_label = train_test_split(data_x, data_y, test_size=0.1, random_state=42)\n","        #print(val_label.type)\n","        #train_dataset,val_dataset = tensordataset_w_indices(train_data, train_label), Data.TensorDataset(val_data, val_label)\n","\n","        return train_data, train_label, val_data, val_label\n","\n","class HAR(Data.Dataset):\n","    def __init__(self, filename_x, filename_y):\n","        self.filename_x = filename_x\n","        self.filename_y = filename_y\n","\n","    def HAR_data(self):\n","        data_x_raw = np.load(self.filename_x)\n","        data_y = np.load(self.filename_y)\n","        data_x = data_x_raw  # (N, C, H, W) (7352, 1, 128, 9)\n","        data_x = data_x.transpose(0, 2, 1)\n","        data_x = X_window_maker(data_x)\n","        data_y = Y_window_maker(data_y)\n","        data_x = torch.tensor(data_x, dtype=torch.float32)\n","        data_y = torch.tensor(data_y, dtype=torch.long)\n","        # data_x = np.expand_dims(data_x_raw, 1)\n","        #print(data_y.type)\n","\n","        #torch_dataset = Data.TensorDataset(data_x, data_y)\n","        return data_x, data_y"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:07.127765Z","iopub.status.busy":"2024-03-18T13:56:07.127446Z","iopub.status.idle":"2024-03-18T13:56:11.105869Z","shell.execute_reply":"2024-03-18T13:56:11.104917Z","shell.execute_reply.started":"2024-03-18T13:56:07.127732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data_x.shape: (6434, 36, 171)\n"]},{"name":"stdout","output_type":"stream","text":["data_x.shape: (1608, 4, 6156)\n","data_y.shape: (1608, 4)\n"]}],"source":["def X_window_maker(x):\n","    remain = x.shape[0] % args.seq_length  # Sliding Window and Permute\n","    x_window = x[remain:].reshape(-1, args.seq_length, x.shape[-1] * x.shape[-2])  # Slice The Remained From Front\n","    return x_window\n","\n","\n","def Y_window_maker(y):\n","    remain = y.shape[0] % args.seq_length\n","    y_window = y[remain:].reshape(-1, args.seq_length)\n","    return y_window\n","\n","import numpy as np\n","\n","#数据上采样部分\n","#data_train = HAR(train_x_list, train_y_list)\n","#data_train = HAR_SMOTE(train_x_list, train_y_list)\n","data_train = trian_HAR(train_x_list, train_y_list)\n","train_data, train_y, val_data, val_y = data_train.HAR_data()\n","data_test = HAR(test_x_list, test_y_list)\n","test_data, test_y = data_test.HAR_data()\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import robust_scale\n","from mne.filter import filter_data\n","\n","def robustscaler(x_tr, x_val, x_ts):\n","    scaler = RobustScaler()\n","    x_tr_sh = x_tr.shape\n","    x_val_sh = x_val.shape\n","    x_ts_sh = x_ts.shape\n","    x_tr = scaler.fit_transform(x_tr.reshape(-1, x_tr_sh[-1]))\n","    x_val = scaler.transform(x_val.reshape(-1, x_val_sh[-1]))\n","    x_ts = scaler.transform(x_ts.reshape(-1, x_ts_sh[-1]))\n","    x_tr = x_tr.reshape(*x_tr_sh)\n","    x_val = x_val.reshape(*x_val_sh)\n","    x_ts = x_ts.reshape(*x_ts_sh)\n","    return x_tr, x_val, x_ts\n","\n","\n","X_tr, X_val, X_ts = robustscaler(train_data, val_data, test_data)\n","[X_tr, X_val, X_ts], [Y_tr_org, Y_val_org, Y_ts_org] = tensor_form([X_tr, X_val, X_ts], [train_y, val_y, test_y])\n","Y_tr_t, Y_val_t, Y_ts_t = label_stage_transition([Y_tr_org, Y_val_org, Y_ts_org])\n","[], [Y_tr_t, Y_val_t, Y_ts_t] = tensor_form([], [Y_tr_t, Y_val_t, Y_ts_t])\n","loss_weight_org = float_tensor(loss_weight_balance(Y_tr_org)).to(device)  # tensor array\n","loss_weight_t = float_tensor(loss_weight_balance(Y_tr_t)).to(device)  # tensor array\n","loss_weight_dict = {'org': loss_weight_org, 'trans': loss_weight_t}\n","\n","tr_loader, val_loader, ts_loader = dataloader_form(X_tr, Y_tr_org, X_val, Y_val_org, X_ts, Y_ts_org)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.107810Z","iopub.status.busy":"2024-03-18T13:56:11.107486Z","iopub.status.idle":"2024-03-18T13:56:11.163650Z","shell.execute_reply":"2024-03-18T13:56:11.162692Z","shell.execute_reply.started":"2024-03-18T13:56:11.107781Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","#from retention import MultiScaleRetention\n","import math\n","import torch\n","import torch.nn as nn\n","device = torch.device(\"cuda\")\n","class EfficientChannelAttention(nn.Module):           # Efficient Channel Attention module\n","    def __init__(self, c, b=1, gamma=2):\n","        super(EfficientChannelAttention, self).__init__()\n","        t = int(abs((math.log(c, 2) + b) / gamma))\n","        k = t if t % 2 else t + 1\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.conv1 = nn.Conv1d(1, 1, kernel_size=k, padding=int(k/2), bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        y = x\n","        x = self.avg_pool(x)\n","        x = self.conv1(x.transpose(-1, -2)).transpose(-1, -2)\n","        out = self.sigmoid(x)\n","        return out+y\n","def fixed_pos_embedding(x):\n","    seq_len, dim = x.shape\n","    inv_freq = 1.0 / (10000 ** (torch.arange(0, dim) / dim))\n","    sinusoid_inp = (\n","        torch.einsum(\"i , j -> i j\", torch.arange(0, seq_len, dtype=torch.float), inv_freq).to(x)\n","    )\n","    return torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)\n","\n","def rotate_every_two(x):\n","    x1 = x[:, :, ::2]\n","    x2 = x[:, :, 1::2]\n","\n","    x = torch.stack((-x2, x1), dim=-1)\n","    return x.flatten(-2)\n","\n","    # in einsum notation: rearrange(x, '... d j -> ... (d j)')\\\n","\n","def duplicate_interleave(m):\n","    \"\"\"\n","    A simple version of `torch.repeat_interleave` for duplicating a matrix while interleaving the copy.\n","    \"\"\"\n","    dim0 = m.shape[0]\n","    m = m.view(-1, 1)  # flatten the matrix\n","    m = m.repeat(1, 2)  # repeat all elements into the 2nd dimension\n","    m = m.view(dim0, -1)  # reshape into a matrix, interleaving the copy\n","    return m\n","\n","def apply_rotary_pos_emb(x, sin, cos, scale=1):\n","    sin, cos = map(lambda t: duplicate_interleave(t * scale), (sin, cos))\n","    # einsum notation for lambda t: repeat(t[offset:x.shape[1]+offset,:], \"n d -> () n () (d j)\", j=2)\n","    return (x * cos) + (rotate_every_two(x) * sin)\n","\n","class XPOS(nn.Module):\n","    def __init__(\n","            self, head_dim, scale_base=512\n","    ):\n","        super().__init__()\n","        self.head_dim = head_dim\n","        self.scale_base = scale_base\n","        self.register_buffer(\n","            \"scale\", (torch.arange(0, head_dim, 2) + 0.4 * head_dim) / (1.4 * head_dim)\n","        )\n","\n","    def forward(self, x, offset=0, downscale=False):\n","        length = x.shape[1]\n","        min_pos = 0\n","        max_pos = length + offset + min_pos\n","        scale = self.scale ** torch.arange(min_pos, max_pos, 1).to(self.scale).div(self.scale_base)[:, None]\n","        sin, cos = fixed_pos_embedding(scale)\n","\n","        if scale.shape[0] > length:\n","            scale = scale[-length:]\n","            sin = sin[-length:]\n","            cos = cos[-length:]\n","\n","        if downscale:\n","            scale = 1 / scale\n","\n","        x = apply_rotary_pos_emb(x, sin, cos, scale)\n","        return x\n","\n","    def forward_reverse(self, x, offset=0, downscale=False):\n","        length = x.shape[1]\n","        min_pos = -(length + offset) // 2\n","        max_pos = length + offset + min_pos\n","        scale = self.scale ** torch.arange(min_pos, max_pos, 1).to(self.scale).div(self.scale_base)[:, None]\n","        sin, cos = fixed_pos_embedding(scale)\n","\n","        if scale.shape[0] > length:\n","            scale = scale[-length:]\n","            sin = sin[-length:]\n","            cos = cos[-length:]\n","\n","        if downscale:\n","            scale = 1 / scale\n","\n","        x = apply_rotary_pos_emb(x, -sin, cos, scale)\n","        return x\n","class SimpleRetention(nn.Module):\n","    def __init__(self, hidden_size, gamma, head_size=None, double_v_dim=False):\n","        \"\"\"\n","        Simple retention mechanism based on the paper\n","        \"Retentive Network: A Successor to Transformer for Large Language Models\"[https://arxiv.org/pdf/2307.08621.pdf]\n","        \"\"\"\n","        super(SimpleRetention, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        if head_size is None:\n","            head_size = hidden_size\n","        self.head_size = head_size\n","\n","        self.v_dim = head_size * 2 if double_v_dim else head_size\n","        self.gamma = gamma\n","        self.W_Q = nn.Parameter(torch.randn(hidden_size, head_size) / hidden_size)\n","        self.W_K = nn.Parameter(torch.randn(hidden_size, head_size) / hidden_size)\n","        self.W_V = nn.Parameter(torch.randn(hidden_size, self.v_dim) / hidden_size)\n","\n","        self.xpos = XPOS(head_size)\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Parallel (default) representation of the retention mechanism.\n","        X: (batch_size, sequence_length, hidden_size)\n","        \"\"\"\n","        sequence_length = X.shape[1]\n","        D = self._get_D(sequence_length)\n","\n","        Q = (X @ self.W_Q)\n","        K = (X @ self.W_K)\n","\n","        Q = self.xpos(Q)\n","        K = self.xpos(K, downscale=True)\n","\n","        V = X @ self.W_V\n","        Q, K, V ,D= Q.to(device), K.to(device), V.to(device),D.to(device)\n","\n","        ret = (Q @ K.permute(0, 2, 1)) * D.unsqueeze(0)\n","\n","        return ret @ V\n","\n","    def forward_recurrent(self, x_n, s_n_1, n):\n","        \"\"\"\n","        Recurrent representation of the retention mechanism.\n","        x_n: (batch_size, 1, hidden_size)\n","        s_n_1: (batch_size, hidden_size, v_dim)\n","        \"\"\"\n","\n","        Q = (x_n @ self.W_Q)\n","        K = (x_n @ self.W_K)\n","\n","        Q = self.xpos(Q, n+1)\n","        K = self.xpos(K, n+1, downscale=True)\n","\n","        V = x_n @ self.W_V\n","\n","        # K: (batch_size, 1, hidden_size)\n","        # V: (batch_size, 1, v_dim)\n","        # s_n = gamma * s_n_1 + K^T @ V\n","\n","        s_n = self.gamma * s_n_1 + (K.transpose(-1, -2) @ V)\n","\n","        return (Q @ s_n), s_n\n","\n","    def forward_chunkwise(self, x_i, r_i_1, i):\n","        \"\"\"\n","        Chunkwise representation of the retention mechanism.\n","        x_i: (batch_size, chunk_size, hidden_size)\n","        r_i_1: (batch_size, hidden_size, v_dim)\n","        \"\"\"\n","        batch, chunk_size, _ = x_i.shape\n","        D = self._get_D(chunk_size)\n","        x_i = x_i.to(self.W_Q.device) \n","        self.W_Q = self.W_Q.to(x_i.device)\n","        self.W_K = self.W_K.to(x_i.device)\n","        Q = (x_i @ self.W_Q)\n","        K = (x_i @ self.W_K)\n","\n","        Q = self.xpos(Q, i * chunk_size)\n","        K = self.xpos(K, i * chunk_size, downscale=True)\n","        \n","        V = x_i @ self.W_V\n","\n","        #print(r_i_1.shape)\n","        r_i_1 = r_i_1[:K.shape[0]]  \n","        r_i =(K.transpose(-1, -2) @ (V * D[-1].view(1, chunk_size, 1))) + (self.gamma ** chunk_size) * r_i_1\n","\n","        inner_chunk = ((Q @ K.transpose(-1, -2)) * D.unsqueeze(0)) @ V\n","\n","        #e[i,j] = gamma ** (i+1)\n","        e = torch.zeros(batch, chunk_size, 1)\n","\n","        for _i in range(chunk_size):\n","            e[:, _i, :] = self.gamma ** (_i + 1)\n","\n","        cross_chunk = (Q @ r_i_1) * e\n","\n","        return inner_chunk + cross_chunk, r_i\n","\n","    def _get_D(self, sequence_length):\n","        n = torch.arange(sequence_length).unsqueeze(1)\n","        m = torch.arange(sequence_length).unsqueeze(0)\n","\n","        # Broadcast self.gamma ** (n - m) with appropriate masking to set values where n < m to 0\n","        D = (self.gamma ** (n - m)) * (n >= m).float()  #this results in some NaN when n is much larger than m\n","        # fill the NaN with 0\n","        D[D != D] = 0\n","\n","        return D\n","\n","\n","\n","class MultiScaleRetention(nn.Module):\n","    def __init__(self, hidden_size, heads, double_v_dim=False):\n","        \"\"\"\n","        Multi-scale retention mechanism based on the paper\n","        \"Retentive Network: A Successor to Transformer for Large Language Models\"[https://arxiv.org/pdf/2307.08621.pdf]\n","        \"\"\"\n","        super(MultiScaleRetention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.v_dim = hidden_size * 2 if double_v_dim else hidden_size\n","        self.heads = heads\n","        assert hidden_size % heads == 0, \"hidden_size must be divisible by heads\"\n","        self.head_size = hidden_size // heads\n","        self.head_v_dim = hidden_size * 2 if double_v_dim else hidden_size\n","\n","        self.gammas = (1 - torch.exp(torch.linspace(math.log(1/32), math.log(1/512), heads))).detach().cpu().tolist()\n","\n","        #self.swish = lambda x: x * torch.sigmoid(x)\n","        self.W_G = nn.Parameter(torch.randn(hidden_size, self.v_dim) / hidden_size)\n","        self.W_O = nn.Parameter(torch.randn(self.v_dim, hidden_size) / hidden_size)\n","        self.group_norm = nn.GroupNorm(heads, self.v_dim)\n","\n","        self.retentions = nn.ModuleList([\n","            SimpleRetention(self.hidden_size, gamma, self.head_size, double_v_dim) for gamma in self.gammas\n","        ])\n","    def swish(self, x):\n","        return x * torch.sigmoid(x)\n","    def forward(self, X):\n","        \"\"\"\n","        parallel representation of the multi-scale retention mechanism\n","        \"\"\"\n","\n","        # apply each individual retention mechanism to X\n","        Y = []\n","        for i in range(self.heads):\n","            Y.append(self.retentions[i](X))\n","\n","        Y = torch.cat(Y, dim=2)\n","        Y_shape = Y.shape\n","        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n","\n","        return (self.swish(X @ self.W_G) * Y) @ self.W_O\n","\n","    def forward_recurrent(self, x_n, s_n_1s, n):\n","        \"\"\"\n","        recurrent representation of the multi-scale retention mechanism\n","        x_n: (batch_size, 1, hidden_size)\n","        s_n_1s: (batch_size, heads, head_size, head_size)\n","\n","        \"\"\"\n","\n","        # apply each individual retention mechanism to a slice of X\n","        Y = []\n","        s_ns = []\n","        for i in range(self.heads):\n","            y, s_n = self.retentions[i].forward_recurrent(\n","                x_n[:, :, :], s_n_1s[i], n\n","            )\n","            Y.append(y)\n","            s_ns.append(s_n)\n","\n","        Y = torch.cat(Y, dim=2)\n","        Y_shape = Y.shape\n","        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n","\n","        return (self.swish(x_n @ self.W_G) * Y) @ self.W_O, s_ns\n","\n","    def forward_chunkwise(self, x_i, r_i_1s, i):\n","        \"\"\"\n","        chunkwise representation of the multi-scale retention mechanism\n","        x_i: (batch_size, chunk_size, hidden_size)\n","        r_i_1s: (batch_size, heads, head_size, head_size)\n","        \"\"\"\n","        batch, chunk_size, _ = x_i.shape\n","\n","        # apply each individual retention mechanism to a slice of X\n","        Y = []\n","        r_is = []\n","        for j in range(self.heads):\n","            y, r_i = self.retentions[j].forward_chunkwise(\n","                x_i[:, :, :], r_i_1s[j], i\n","            )\n","            Y.append(y)\n","            r_is.append(r_i)\n","\n","\n","        Y = torch.cat(Y, dim=2)\n","        Y_shape = Y.shape\n","        Y = self.group_norm(Y.reshape(-1, self.v_dim)).reshape(Y_shape)\n","        x_i = x_i.to(self.W_G.device)\n","        return (self.swish(x_i @ self.W_G) * Y) @ self.W_O, r_is\n","\n","class RetNet(nn.Module):\n","    def __init__(self, layers, hidden_dim, ffn_size, heads, double_v_dim=False):\n","        super(RetNet, self).__init__()\n","        self.layers = layers\n","        self.hidden_dim = hidden_dim\n","        self.ffn_size = ffn_size\n","        self.heads = heads\n","        self.v_dim = hidden_dim * 2 if double_v_dim else hidden_dim\n","\n","        self.retentions = nn.ModuleList([\n","            MultiScaleRetention(hidden_dim, heads, double_v_dim)\n","            for _ in range(layers)\n","        ])\n","        self.ffns = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Linear(hidden_dim, ffn_size),\n","                nn.GELU(),\n","                nn.Linear(ffn_size, hidden_dim)\n","            )\n","            for _ in range(layers)\n","        ])\n","        self.layer_norms_1 = nn.ModuleList([\n","            nn.LayerNorm(hidden_dim)\n","            for _ in range(layers)\n","        ])\n","        self.layer_norms_2 = nn.ModuleList([\n","            nn.LayerNorm(hidden_dim)\n","            for _ in range(layers)\n","        ])\n","\n","    def forward(self, X):\n","        \"\"\"\n","        X: (batch_size, sequence_length, hidden_size)\n","        \"\"\"\n","        for i in range(self.layers):\n","            Y = self.retentions[i](self.layer_norms_1[i](X)) + X\n","\n","            X = self.ffns[i](self.layer_norms_2[i](Y)) + Y\n","\n","        return X\n","\n","    def forward_recurrent(self, x_n, s_n_1s, n):\n","        \"\"\"\n","        X: (batch_size, sequence_length, hidden_size)\n","        s_n_1s: list of lists of tensors of shape (batch_size, hidden_size // heads, hidden_size // heads)\n","\n","        \"\"\"\n","        s_ns = []\n","        for i in range(self.layers):\n","            # list index out of range\n","            o_n, s_n = self.retentions[i].forward_recurrent(self.layer_norms_1[i](x_n), s_n_1s[i], n)\n","            y_n = o_n + x_n\n","            s_ns.append(s_n)\n","            x_n = self.ffns[i](self.layer_norms_2[i](y_n)) + y_n\n","\n","        return x_n, s_ns\n","\n","    def forward_chunkwise(self, x_i, r_i_1s, i):\n","        \"\"\"\n","        X: (batch_size, sequence_length, hidden_size)\n","        r_i_1s: list of lists of tensors of shape (batch_size, hidden_size // heads, hidden_size // heads)\n","\n","        \"\"\"\n","        r_is = []\n","        for j in range(self.layers):\n","            o_i, r_i = self.retentions[j].forward_chunkwise(self.layer_norms_1[j](x_i), r_i_1s[j], i)\n","            y_i = o_i + x_i\n","            r_is.append(r_i)\n","            x_i = self.ffns[j](self.layer_norms_2[j](y_i)) + y_i\n","\n","        return x_i, r_is\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.165311Z","iopub.status.busy":"2024-03-18T13:56:11.164943Z","iopub.status.idle":"2024-03-18T13:56:11.181844Z","shell.execute_reply":"2024-03-18T13:56:11.180870Z","shell.execute_reply.started":"2024-03-18T13:56:11.165277Z"},"trusted":true},"outputs":[],"source":["#batch_size = 512\n","#train_dataloader = DataLoader(dataset=tr_loader, batch_size=batch_size, pin_memory=True, shuffle=True,drop_last=True, num_workers=2,)\n","#test_dataloader = DataLoader(dataset=ts_loader, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n","#val_dataloader = DataLoader(dataset=val_loader, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=2,)\n","def train(network, tr_loader, val_loader, optimizer1, num_epochs=50, loss_weight=None, Y_t=None):\n","    # 定义损失函数和优化器.\n","\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    criterion1 = nn.CrossEntropyLoss()\n","    # 定义在验证集上表现最好的模型准确率和损失.\n","    best_val_acc = 0.0\n","    best_val_loss = float('inf')\n","    Best_epoch = 0\n","    #定义存储最佳模型参数的变量.\n","    best_model_params = None\n","    # 开始训练模型.\n","    for epoch in range(num_epochs):\n","        train_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","        network.train()\n","        \n","        for (x, y), idx in tr_loader:\n","            x, y, y_t = x.to(device), y.flatten().to(device), Y_t[idx].flatten().to(device)\n","            \n","            optimizer1.opt_zero_grad()\n","            #optimizer2.zero_grad()\n","\n","            \n","            l_2 = network(x)\n","            \n","            #print(l_2.shape)\n","            #print(y.shape)\n","            loss = args.lambda_cls*loss_cross_entropy(weight=loss_weight['org'])(l_2, y)\n","            \n","            _, predicted = torch.max(l_2.data, 1)\n","            train_correct += (predicted == y).sum().item()\n","            train_total += y.size(0)\n","            # 累计训练损失\n","            #scaler.scale(loss).backward()\n","            #scaler.step(optimizer1)\n","\n","            #scaler.update()\n","            loss.backward()\n","            optimizer1.opt_step()\n","            #optimizer2.step()\n","            train_loss += loss.item()\n","            print(\">\", end=\"\")\n","        # 计算训练准确率和损失.\n","        train_acc = 100.0 * train_correct / train_total\n","        train_loss = train_loss / len(tr_loader)\n","\n","        # 在验证集上验证模型.\n","        #val_loss = 0.0\n","        val_correct = 0\n","        val_total = 0\n","        network.eval()\n","        with torch.no_grad():\n","            for iteration, batch in enumerate(zip(val_loader)):\n","\n","                x, y = batch[0]\n","                x, y = x.to(device), y.flatten().to(device)\n","\n","                # 前向传播.\n","                l_2 = network(x)\n","                # 计算损失和准确率.\n","\n","                _, predicted = torch.max(l_2.data, 1)\n","                val_correct += (predicted == y).sum().item()\n","                val_total += y.size(0)\n","\n","                # 累计验证损失.\n","                #val_loss += loss.item()\n","\n","        # 计算验证准确率和损失.\n","        val_acc = 100.0 * val_correct / val_total\n","        #val_loss = val_loss / len(val_loader)\n","        if val_acc > best_val_acc:\n","            Best_epoch = epoch + 1\n","            best_val_acc = val_acc\n","            #best_val_loss = val_loss\n","            best_model_params = network.state_dict()\n","\n","        print()\n","        # 打印训练和验证结果.\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%,Val Acc: {:.2f}%'\n","              .format(epoch + 1, num_epochs, train_loss, train_acc, val_acc))\n","\n","        # 保存训练和验证结果.\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        #val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","    print(\"The best epoch:\", Best_epoch, \"    Acc:\", best_val_acc)\n","    network.load_state_dict(best_model_params)\n","    # 返回训练和验证结果.\n","    return network.eval(), train_loss_list, train_acc_list, val_acc_list"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.183585Z","iopub.status.busy":"2024-03-18T13:56:11.183249Z","iopub.status.idle":"2024-03-18T13:56:11.198717Z","shell.execute_reply":"2024-03-18T13:56:11.197844Z","shell.execute_reply.started":"2024-03-18T13:56:11.183551Z"},"trusted":true},"outputs":[],"source":["def train2(network, tr_loader, val_loader, optimizer1, num_epochs=50, loss_weight=None, Y_t=None):\n","    # 定义损失函数和优化器.\n","\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    criterion1 = nn.CrossEntropyLoss()\n","    # 定义在验证集上表现最好的模型准确率和损失.\n","    best_val_acc = 0.0\n","    best_val_loss = float('inf')\n","    Best_epoch = 0\n","    #定义存储最佳模型参数的变量.\n","    best_model_params = None\n","    # 开始训练模型.\n","    for epoch in range(num_epochs):\n","        train_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","        network.train()\n","        \n","        for (x, y), idx in tr_loader:\n","            x, y, y_t = x.to(device), y.flatten().to(device), Y_t[idx].flatten().to(device)\n","            \n","            optimizer1.opt_zero_grad()\n","            #optimizer2.zero_grad()\n","\n","            \n","            l_2 = network(x)\n","            \n","            #print(l_2.shape)\n","            #print(y.shape)\n","            loss = args.lambda_cls*loss_cross_entropy(weight=loss_weight['org'])(l_2, y)\n","            \n","            _, predicted = torch.max(l_2.data, 1)\n","            train_correct += (predicted == y).sum().item()\n","            train_total += y.size(0)\n","            # 累计训练损失\n","            #scaler.scale(loss).backward()\n","            #scaler.step(optimizer1)\n","\n","            #scaler.update()\n","            loss.backward()\n","            optimizer1.opt_step()\n","            #optimizer2.step()\n","            train_loss += loss.item()\n","            print(\">\", end=\"\")\n","        # 计算训练准确率和损失.\n","        train_acc = 100.0 * train_correct / train_total\n","        train_loss = train_loss / len(tr_loader)\n","\n","        # 在验证集上验证模型.\n","        #val_loss = 0.0\n","        val_correct = 0\n","        val_total = 0\n","        network.eval()\n","        with torch.no_grad():\n","            for iteration, batch in enumerate(zip(val_loader)):\n","\n","                x, y = batch[0]\n","                x, y = x.to(device), y.flatten().to(device)\n","\n","                # 前向传播.\n","                l_2 = network(x)\n","                # 计算损失和准确率.\n","\n","                _, predicted = torch.max(l_2.data, 1)\n","                val_correct += (predicted == y).sum().item()\n","                val_total += y.size(0)\n","\n","                # 累计验证损失.\n","                #val_loss += loss.item()\n","\n","        # 计算验证准确率和损失.\n","        val_acc = 100.0 * val_correct / val_total\n","        #val_loss = val_loss / len(val_loader)\n","        if val_acc > best_val_acc:\n","            Best_epoch = epoch + 1\n","            best_val_acc = val_acc\n","            #best_val_loss = val_loss\n","            best_model_params = network.state_dict()\n","\n","        print()\n","        # 打印训练和验证结果.\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%,Val Acc: {:.2f}%'\n","              .format(epoch + 1, num_epochs, train_loss, train_acc, val_acc))\n","\n","        # 保存训练和验证结果.\n","        train_loss_list.append(train_loss)\n","        train_acc_list.append(train_acc)\n","        #val_loss_list.append(val_loss)\n","        val_acc_list.append(val_acc)\n","    print(\"The best epoch:\", Best_epoch, \"    Acc:\", best_val_acc)\n","    network.load_state_dict(best_model_params)\n","    # 返回训练和验证结果.\n","    return network.eval(), train_loss_list, train_acc_list, val_acc_list"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.200084Z","iopub.status.busy":"2024-03-18T13:56:11.199773Z","iopub.status.idle":"2024-03-18T13:56:11.211030Z","shell.execute_reply":"2024-03-18T13:56:11.210165Z","shell.execute_reply.started":"2024-03-18T13:56:11.200058Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["print(args.lambda_cls)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.289193Z","iopub.status.busy":"2024-03-18T13:56:11.288913Z","iopub.status.idle":"2024-03-18T13:56:11.328242Z","shell.execute_reply":"2024-03-18T13:56:11.327199Z","shell.execute_reply.started":"2024-03-18T13:56:11.289169Z"},"trusted":true},"outputs":[],"source":["import copy\n","import math\n","#from utils import *\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","import torch.nn as nn\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self, in_f, out_f):\n","        '''\n","        Classify FE feature\n","        '''\n","        super(Classifier, self).__init__()\n","        self.linear_1 = nn.Linear(in_f, out_f)  # 创建一个nn.Linear实例，并将其赋值给self.linear_1，输入的参数为in_f和out_f\n","\n","    def forward(self, x):\n","        x = self.linear_1(x)  # 将输入张量x通过self.linear_1处理得到输出张量\n","        return x\n","\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=args.seq_length):\n","\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        if args.scheme == 'M_O': max_len = max_len // 2 + 1 \n","        pe = torch.zeros(max_len, d_model) \n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(\n","            1)  \n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (\n","                    -math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        if args.scheme == 'M_O': pe = torch.cat(\n","            [pe, pe.flip(dims=(0, 1))[1:]])\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","\n","class MSNN_Feature_Embedding_Two_Way(nn.Module):\n","    def __init__(self):\n","        super(MSNN_Feature_Embedding_Two_Way, self).__init__()\n","        # 定义卷积、可分离卷积\n","        conv = lambda in_f, out_f, kernel, s=None: nn.Sequential(nn.Conv1d(in_f, out_f, (kernel,), stride=s),\n","                                                                 nn.BatchNorm1d(out_f), nn.LeakyReLU())\n","        sepconv_same = lambda in_f, out_f, kernel: nn.Sequential(\n","            nn.Conv1d(in_f, out_f, (kernel,), padding=int(kernel / 2), groups=in_f),\n","            nn.Conv1d(out_f, out_f, (1,)), nn.BatchNorm1d(out_f), nn.LeakyReLU())\n","\n","        self.conv_A_0 = conv(1, 4, 5, 1)\n","        self.sepconv_A_1 = sepconv_same(4, 16, 9)\n","        self.sepconv_A_2 = sepconv_same(16, 32, 5)\n","        self.sepconv_A_3 = sepconv_same(32, 64, 3) \n","\n","        self.conv_B_0 = conv(1, 4, 10, 1)  \n","        self.sepconv_B_1 = sepconv_same(4, 16, 9) \n","        self.sepconv_B_2 = sepconv_same(16, 32, 5) \n","        self.sepconv_B_3 = sepconv_same(32, 64, 3) \n","        \n","        self.conv_C_0 = conv(1, 4, 20, 1)  \n","        self.sepconv_C_1 = sepconv_same(4, 16, 9) \n","        self.sepconv_C_2 = sepconv_same(16, 32, 5) \n","        self.sepconv_C_3 = sepconv_same(32, 64, 3) \n","        self.ATT = EfficientChannelAttention(112)\n","        self.gap = nn.AdaptiveAvgPool1d(args.mha_length)  \n","        self.pe = PositionalEncoding(112,\n","                                     max_len=args.mha_length)\n","        self.mha_ff_A = nn.TransformerEncoderLayer(112, args.mha_head,\n","                                                   dim_feedforward=448)\n","        self.mha_ff_B = nn.TransformerEncoderLayer(112, args.mha_head,\n","                                                   dim_feedforward=448) \n","        self.mha_ff_C = nn.TransformerEncoderLayer(112, args.mha_head,\n","                                                   dim_feedforward=448) \n","\n","    def seq_trans(self, func, x):\n","        # 输入形状：[B, F, T]\n","        return func(x.permute(-1, 0, 1)).permute(1, -1, 0)\n","\n","    def one_way(self, conv_0, sepconv_1, sepconv_2, sepconv_3, x, mha_ff=None,att = None):\n","        b, l, t = x.shape\n","        x = x.reshape(-1, 1, t) #[B*F,1,T]\n","        x = conv_0(x)\n","        x = sepconv_1(x)\n","        x1 = x\n","        x = sepconv_2(x) \n","        x2 = x\n","        x = sepconv_3(x) \n","        x3 = x\n","        x = self.gap(torch.cat([x1, x2, x3], 1))\n","        t = self.ATT(x)\n","        if att !=None:\n","            x = self.ATT(x+att)\n","        att = t+x\n","        x = x + self.seq_trans(self.pe, x) \n","        x = x.permute(-1, 0, 1) #[T,B*F,F]\n","        x = mha_ff(x).permute(1, -1, 0) \n","        x = x.reshape(b, l, *x.shape[-2:]) \n","\n","        return x , att\n","    def one_way0(self, conv_0, sepconv_1, sepconv_2, sepconv_3, x, mha_ff=None,att = None):\n","        #print(x.shape)\n","        b, l, t = x.shape\n","        x = x.reshape(-1, 1, t) #[B*F,1,T]\n","        #print(x.shape)\n","        x = conv_0(x)\n","        x = sepconv_1(x)\n","        x1 = x\n","        x = sepconv_2(x) \n","        x2 = x\n","        x = sepconv_3(x) \n","        x3 = x\n","        #print(x.shape)\n","        x = self.gap(torch.cat([x1, x2, x3], 1))\n","        #print(x.shape)\n","        x = x + self.seq_trans(self.pe, x) \n","        #print(x.shape)\n","        x = x.permute(-1, 0, 1) #[T,B*F,F]\n","        #print(x.shape)\n","        x = mha_ff(x).permute(1, -1, 0)\n","        #print(x.shape)\n","        x = x.reshape(b, l, *x.shape[-2:]) \n","        #print(x.shape)\n","\n","        return x\n","\n","    def forward(self, x):\n","        x_A = self.one_way0(self.conv_A_0, self.sepconv_A_1, self.sepconv_A_2, self.sepconv_A_3, x,\n","                           mha_ff=self.mha_ff_A) \n","        x_B ,att= self.one_way(self.conv_B_0, self.sepconv_B_1, self.sepconv_B_2, self.sepconv_B_3, x,\n","                           mha_ff=self.mha_ff_B)\n","        x_C ,att= self.one_way(self.conv_C_0, self.sepconv_C_1, self.sepconv_C_2, self.sepconv_C_3, x,\n","                           mha_ff=self.mha_ff_C,att = att)\n","        x = torch.cat((x_A, x_B,x_C), dim=-2) \n","        return x\n","#############################################################################################################################\n","\n","class Context_Encoder(nn.Module):\n","    def __init__(self, f, h):\n","        super(Context_Encoder, self).__init__()\n","\n","        self.biLSTM = nn.LSTM(f, h, num_layers=args.lstm_layers, bidirectional=True,batch_first=True)\n","        self.biLSTM = nn.LSTM(f, h ,num_layers=args.lstm_layers, dropout=0.5, bidirectional=True,batch_first=True)\n","        self.dropout_1 = nn.Dropout() \n","        self.dropout_2 = nn.Dropout() \n","        self.MR1 = RetNet(layers=1, hidden_dim=f, ffn_size=h, heads=16, double_v_dim=False)\n","        \n","    def forward(self, x):  # [B, L, F]\n","        \n","        h, _ = self.biLSTM(x)  \n","        h = self.dropout_1(h) \n","        h = h+x\n","        h = self.dropout_2(h) \n","        return h\n","    def forward_ret(self, x): \n","        h = self.MR1(x)  \n","        h = self.dropout_1(h) \n","        h = h+x\n","        h = self.dropout_2(h) \n","        return h\n","#############################################################################################################################\n","\n","class Model(nn.Module):\n","    def __init__(self, x, num_classes=12):\n","        super(Model, self).__init__()\n","        self.FE = MSNN_Feature_Embedding_Two_Way().to(device)\n","        with torch.no_grad():\n","            b, l, f, t = self.FE(x).shape \n","            feature_size = f * t  \n","            embedding_size = int(feature_size / 2)\n","\n","        self.Context_Encoder = Context_Encoder(feature_size, embedding_size).to(device) \n","        with torch.no_grad(): \n","            x = self.FE(x)\n","            x = x.flatten(start_dim=2)\n","            feature_size2 = self.Context_Encoder(x).shape[-1]\n","        self.project_f = nn.Linear(feature_size,feature_size2) \n","        self.dropout = nn.Dropout()\n","        self.cls = Classifier(feature_size2, num_classes)\n","\n","    def forward(self, x):\n","        x = x.to(device)\n","#         print(x.shape)\n","        x = network.FE(x)\n","#         print(x.shape)\n","\n","        b, l, f, t = x.shape  # 计算输入张量x的形状\n","        x = x.view(b,l, f*t)\n","#         print(x.shape)\n","        h = network.Context_Encoder.forward_ret(x)\n","#         print(h.shape)\n","        l_2 = network.cls(h.to(device)) \n","        l_2 = l_2.flatten(end_dim=1)\n","#         print(l_2.shape)\n","\n","        return l_2"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-18T13:56:11.345769Z","iopub.status.busy":"2024-03-18T13:56:11.345483Z","iopub.status.idle":"2024-03-18T13:56:14.446428Z","shell.execute_reply":"2024-03-18T13:56:14.444858Z","shell.execute_reply.started":"2024-03-18T13:56:11.345743Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'EfficientChannelAttention' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Y_t \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m: Y_tr_t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: Y_val_t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts\u001b[39m\u001b[38;5;124m'\u001b[39m: Y_ts_t}\n\u001b[0;32m----> 2\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtr_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# network = CNN(x=tr_loader.dataset.tensors[0][:2].to(device), num_classes=12).to(device)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# network = LSTM(x=tr_loader.dataset.tensors[0][:2].to(device), input_size=1, hidden_size=32, num_layers=6, output_size=12).to(device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# network = Model(x=tr_loader.dataset.tensors[0][:2].to(device)).to(device)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 173\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, x, num_classes)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFE \u001b[38;5;241m=\u001b[39m \u001b[43mMSNN_Feature_Embedding_Two_Way\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    175\u001b[0m         b, l, f, t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFE(x)\u001b[38;5;241m.\u001b[39mshape \n","Cell \u001b[0;32mIn[9], line 72\u001b[0m, in \u001b[0;36mMSNN_Feature_Embedding_Two_Way.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msepconv_C_2 \u001b[38;5;241m=\u001b[39m sepconv_same(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m5\u001b[39m) \n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msepconv_C_3 \u001b[38;5;241m=\u001b[39m sepconv_same(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m) \n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mATT \u001b[38;5;241m=\u001b[39m \u001b[43mEfficientChannelAttention\u001b[49m(\u001b[38;5;241m112\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgap \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool1d(args\u001b[38;5;241m.\u001b[39mmha_length)  \n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe \u001b[38;5;241m=\u001b[39m PositionalEncoding(\u001b[38;5;241m112\u001b[39m,\n\u001b[1;32m     75\u001b[0m                              max_len\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmha_length)\n","\u001b[0;31mNameError\u001b[0m: name 'EfficientChannelAttention' is not defined"]}],"source":["Y_t = {'tr': Y_tr_t, 'val': Y_val_t, 'ts': Y_ts_t}\n","network = Model(x=tr_loader.dataset.tensors[0][:2].to(device)).to(device)\n","# network = CNN(x=tr_loader.dataset.tensors[0][:2].to(device), num_classes=12).to(device)\n","# network = LSTM(x=tr_loader.dataset.tensors[0][:2].to(device), input_size=1, hidden_size=32, num_layers=6, output_size=12).to(device)\n","# network = Model(x=tr_loader.dataset.tensors[0][:2].to(device)).to(device)\n","import time\n","opt = Optimizer(network)\n","\n","\n","start_time = time.time()\n","model, train_loss_list, train_acc_list, val_acc_list = \\\n","    train(network=network, tr_loader=tr_loader, val_loader=val_loader, num_epochs=50, optimizer1=opt,\n","          loss_weight=loss_weight_dict, Y_t=Y_t['tr'])\n","end_time = time.time()\n","use_time = end_time - start_time\n","print(\"Train and val complete in {:.0f}m {:.0f}s\".format(use_time // 60, use_time % 60))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model, 'msc_pamap2_model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.447546Z","iopub.status.idle":"2024-03-18T13:56:14.448037Z","shell.execute_reply":"2024-03-18T13:56:14.447797Z","shell.execute_reply.started":"2024-03-18T13:56:14.447776Z"},"trusted":true},"outputs":[],"source":["\n","# def plot_loss_and_acc(train_loss_list, train_acc_list, val_acc_list):\n","#     # 绘制训练和验证损失\n","#     plt.figure(figsize=(10, 5))\n","#     plt.plot(train_loss_list, label='train_loss')\n","#     #plt.plot(val_loss_list, label='val_loss')\n","#     plt.title('Training and Validation Loss')\n","#     plt.xlabel('Epoch')\n","#     plt.ylabel('Loss')\n","#     plt.legend()\n","#     plt.show()\n","\n","#     # 绘制训练和验证准确率\n","#     plt.figure(figsize=(10, 5))\n","#     plt.plot(train_acc_list, label='train_acc')\n","#     plt.plot(val_acc_list, label='val_acc')\n","#     plt.title('Training and Validation Accuracy')\n","#     plt.xlabel('Epoch')\n","#     plt.ylabel('Accuracy')\n","#     plt.legend()\n","#     plt.show()\n","\n","\n","# plot_loss_and_acc(train_loss_list, train_acc_list, val_acc_list)\n","# from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.449065Z","iopub.status.idle":"2024-03-18T13:56:14.449505Z","shell.execute_reply":"2024-03-18T13:56:14.449318Z","shell.execute_reply.started":"2024-03-18T13:56:14.449296Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import classification_report\n","def test_final(model, test_dataloader, loss_weight=0.007):\n","    # 将模型设置为测试模式.\n","    model.eval()\n","\n","    # 定义损失函数和优化器.\n","    criterion1 = nn.CrossEntropyLoss()\n","    #criterion2 = CenterLoss(6, 6).to(device)\n","\n","    loss_weight = 0.007\n","    # 在测试集上测试模型.\n","    test_loss = 0.0\n","    test_correct = 0\n","    test_total = 0\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for iteration, batch in enumerate(zip(val_loader)):\n","            x, y = batch[0]\n","            x, y = x.to(device), y.flatten().to(device)\n","\n","            # 前向传播.\n","            l_2 = network(x)\n","\n","            pre_lab = torch.argmax(l_2, 1)\n","            # 计算损失和准确率.\n","            #loss = criterion1(outputs, labels)\n","            #loss = criterion1(l_2, y)# + loss_weight * criterion2(labels, outputs)\n","            _, predicted = torch.max(l_2.data, 1)\n","            test_correct += (predicted == y).sum().item()\n","            test_total += y.size(0)\n","\n","            # 累计测试损失.\n","            #test_loss += loss.item()\n","            y_true.extend(y.tolist())\n","            y_pred.extend(pre_lab.tolist())\n","    report = classification_report(y_true, y_pred, digits=4)\n","    # 计算测试准确率和损失.\n","    test_acc = 100.0 * test_correct / test_total\n","    #test_loss = test_loss / len(test_dataloader)\n","\n","    # 打印测试结果.\n","    print('Test Acc: {:.2f}%'.format(test_acc))\n","    print(report)\n","    # 返回测试结果.\n","    return test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.450758Z","iopub.status.idle":"2024-03-18T13:56:14.451235Z","shell.execute_reply":"2024-03-18T13:56:14.451024Z","shell.execute_reply.started":"2024-03-18T13:56:14.450982Z"},"trusted":true},"outputs":[],"source":["test_acc = test_final(network, ts_loader, loss_weight=0.007, )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.452514Z","iopub.status.idle":"2024-03-18T13:56:14.452854Z","shell.execute_reply":"2024-03-18T13:56:14.452705Z","shell.execute_reply.started":"2024-03-18T13:56:14.452688Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.font_manager import FontProperties\n","from matplotlib.ticker import PercentFormatter\n","class DrawConfusionMatrix:\n","    def __init__(self, labels_name, normalize=True):\n","        self.normalize = normalize\n","        self.labels_name = labels_name\n","        self.num_classes = len(labels_name)\n","        self.matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"float32\")\n","        self.class_counts_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int32\")\n","\n","    def update(self, labels, predicts):\n","        for predict, label in zip(labels, predicts):\n","            self.matrix[label, predict] += 1\n","            self.class_counts_matrix[label, predict] += 1\n","\n","    def getMatrix(self, normalize=True):\n","        if normalize:\n","            per_sum = self.matrix.sum(axis=1)  # 计算每行的和，用于百分比计算\n","            for i in range(self.num_classes):\n","                self.matrix[i] = (self.matrix[i] / per_sum[i])  # 百分比转换\n","            self.matrix = np.around(self.matrix, 4)  # 保留4位小数点\n","            self.matrix[np.isnan(self.matrix)] = 0.0  # 可能存在NaN，将其设为0\n","        return self.matrix\n","\n","    def drawMatrix(self):\n","        self.matrix = self.getMatrix(self.normalize)\n","        font = FontProperties(family='serif', style='normal', weight='normal', size=10)\n","        plt.figure(dpi=240)\n","        plt.imshow(self.matrix, cmap=plt.cm.Blues)  # 仅画出颜色格子，没有值\n","        plt.title(\"PAMAP2\", fontproperties=font)  # 标题\n","        plt.xlabel(\"Predict label\", fontproperties=font)\n","        plt.ylabel(\"Truth label\", fontproperties=font)\n","\n","        plt.yticks(range(self.num_classes), self.labels_name, fontproperties=font)  # y轴标签\n","        plt.xticks(range(self.num_classes), self.labels_name, rotation=30, fontproperties=font)  # x轴标签\n","        thresh = self.matrix.max() / 2.\n","\n","        for x in range(self.num_classes):\n","            for y in range(self.num_classes):\n","                count = self.class_counts_matrix[y, x]\n","                value = str(format('%.2f' % float(self.matrix[y, x] * 100.00))) + '%'  # 数值处理\n","                #text = f\"{count}\\n{value}\"\n","                text = count\n","                plt.text(x, y-0.13, text, verticalalignment='center',\n","                         horizontalalignment='center',\n","                         color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=8)  # 写值\n","                plt.text(x, y+0.13, value, verticalalignment='center',\n","                         horizontalalignment='center',\n","                         color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=8)  # 写值\n","\n","        plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域\n","\n","        #色条\n","        plt.colorbar(format=PercentFormatter(xmax=1, decimals=0, symbol='%', is_latex=False))\n","        plt.savefig('./ConfusionMatrix.png', bbox_inches='tight')  # bbox_inches='tight'可确保标签信息显示全\n","        plt.show()\n","\n","\n","def printMatrix(test_loader, model):\n","#     labels_name = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n","#     labels_name=[\"Walking\", \"Upstairs\", \"Downstairs\", \"Sitting\", \"Standing\", \"Laying\"]\n","    labels_name=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n","\n","    drawconfusionmatrix = DrawConfusionMatrix(labels_name=labels_name)  # 实例化\n","    for index, (imgs, labels) in enumerate(test_loader, 1):\n","#         x, y, y_t = x.to(device), y.flatten().to(device), Y_t[idx].flatten().to(device)\n","        imgs, labels = imgs.to(device), labels.flatten().to(device)\n","        labels_pd = model(imgs.float())     \n","        predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)  # array([0,5,1,6,3,...],dtype=int64)\n","        labels_np = labels.cpu().numpy()-1  # array([0,5,0,6,2,...],dtype=int64)\n","        drawconfusionmatrix.update(labels_np, predict_np)  # 将新批次的predict和label更新（保存）\n","\n","    drawconfusionmatrix.drawMatrix()  # 根据所有predict和label，画出混淆矩阵\n","\n","    confusion_mat = drawconfusionmatrix.getMatrix()  # 你也可以使用该函数获取混淆矩阵(ndarray)\n","    print(confusion_mat)\n","\n","print(\"开始绘制混淆矩阵\")\n","printMatrix(ts_loader, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.454272Z","iopub.status.idle":"2024-03-18T13:56:14.454611Z","shell.execute_reply":"2024-03-18T13:56:14.454461Z","shell.execute_reply.started":"2024-03-18T13:56:14.454445Z"},"trusted":true},"outputs":[],"source":["# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from matplotlib.font_manager import FontProperties\n","# from matplotlib.ticker import PercentFormatter\n","\n","# class DrawConfusionMatrix:\n","#     def __init__(self, labels_name, normalize=True):\n","#         self.normalize = normalize\n","#         self.labels_name = labels_name\n","#         self.num_classes = len(labels_name)\n","#         self.matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"float32\")\n","#         self.class_counts_matrix = np.zeros((self.num_classes, self.num_classes), dtype=\"int32\")\n","\n","#     def update(self, labels, predicts):\n","#         for predict, label in zip(labels, predicts):\n","#             self.matrix[label, predict] += 1\n","#             self.class_counts_matrix[label, predict] += 1\n","\n","#     def getMatrix(self, normalize=True):\n","#         if normalize:\n","#             per_sum = self.matrix.sum(axis=1)  # 计算每行的和，用于百分比计算\n","#             for i in range(self.num_classes):\n","#                 self.matrix[i] = (self.matrix[i] / per_sum[i])  # 百分比转换\n","#             self.matrix = np.around(self.matrix, 4)  # 保留4位小数点\n","#             self.matrix[np.isnan(self.matrix)] = 0.0  # 可能存在NaN，将其设为0\n","#         return self.matrix\n","\n","#     def drawMatrix(self):\n","#         self.matrix = self.getMatrix(self.normalize)\n","#         font = FontProperties(family='serif', style='normal', weight='normal', size=10)\n","#         plt.figure(dpi=480)\n","#         plt.imshow(self.matrix, cmap=plt.cm.Blues)  # 仅画出颜色格子，没有值\n","#         plt.title(\"PAMAP2\", fontproperties=font)  # 标题\n","#         plt.xlabel(\"Predict label\", fontproperties=font)\n","#         plt.ylabel(\"Truth label\", fontproperties=font)\n","\n","#         plt.yticks(range(self.num_classes), self.labels_name, fontproperties=font)  # y轴标签\n","#         plt.xticks(range(self.num_classes), self.labels_name, rotation=0, fontproperties=font)  # x轴标签\n","#         thresh = self.matrix.max() / 2.\n","\n","#         for x in range(self.num_classes):\n","#             for y in range(self.num_classes):\n","#                 count = self.class_counts_matrix[y, x]\n","#                 #value = str(format('%.2f' % float(self.matrix[y, x] * 100.00))) + '%'  # 数值处理\n","#                 #text = f\"{count}\\n{value}\"\n","#                 text = count\n","#                 plt.text(x, y, text, verticalalignment='center',\n","#                          horizontalalignment='center',\n","#                          color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=6)  # 写值\n","# #                 plt.text(x, y+0.13, value, verticalalignment='center',\n","# #                          horizontalalignment='center',\n","# #                          color=\"white\" if self.matrix[y, x] > thresh else \"black\", fontproperties=font, fontsize=8)  # 写值\n","\n","#         plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域\n","\n","#         #色条\n","#         plt.clim(0, 1.0)\n","#         plt.colorbar(format=PercentFormatter(xmax=1, decimals=0, symbol='%', is_latex=False))\n","#         plt.savefig('./ConfusionMatrix.png', bbox_inches='tight')  # bbox_inches='tight'可确保标签信息显示全\n","#         plt.show()\n","\n","\n","# def printMatrix(test_loader, model):\n","# #     labels_name = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n","# #     labels_name=[\"Walking\", \"Upstairs\", \"Downstairs\", \"Sitting\", \"Standing\", \"Laying\"]\n","#     labels_name=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n","\n","#     drawconfusionmatrix = DrawConfusionMatrix(labels_name=labels_name)  # 实例化\n","#     for index, (imgs, labels) in enumerate(test_loader, 1):\n","#         labels_pd = model(imgs.float())\n","#         predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)  # array([0,5,1,6,3,...],dtype=int64)\n","#         labels_np = labels.numpy()  # array([0,5,0,6,2,...],dtype=int64)\n","#         drawconfusionmatrix.update(labels_np, predict_np)  # 将新批次的predict和label更新（保存）\n","\n","#     drawconfusionmatrix.drawMatrix()  # 根据所有predict和label，画出混淆矩阵\n","\n","#     confusion_mat = drawconfusionmatrix.getMatrix()  # 你也可以使用该函数获取混淆矩阵(ndarray)\n","#     print(confusion_mat)\n","\n","# print(\"开始绘制混淆矩阵\")\n","# printMatrix(ts_loader, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-18T13:56:14.456271Z","iopub.status.idle":"2024-03-18T13:56:14.456656Z","shell.execute_reply":"2024-03-18T13:56:14.456487Z","shell.execute_reply.started":"2024-03-18T13:56:14.456468Z"},"trusted":true},"outputs":[],"source":["torch.save({'model': model.state_dict()}, 'model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3769549,"sourceId":6520361,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
