{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-11T06:21:00.751900Z","iopub.status.busy":"2024-02-11T06:21:00.751525Z","iopub.status.idle":"2024-02-11T06:21:01.116701Z","shell.execute_reply":"2024-02-11T06:21:01.115800Z","shell.execute_reply.started":"2024-02-11T06:21:00.751869Z"},"metadata":{},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:01.119651Z","iopub.status.busy":"2024-02-11T06:21:01.118847Z","iopub.status.idle":"2024-02-11T06:21:01.124444Z","shell.execute_reply":"2024-02-11T06:21:01.123048Z","shell.execute_reply.started":"2024-02-11T06:21:01.119616Z"},"metadata":{},"trusted":true},"outputs":[],"source":["# x_train_path = \"/kaggle/input/wisdm-data/wisdm/x_train.npy\"\n","# y_train_path = \"/kaggle/input/wisdm-data/wisdm/y_train.npy\"\n","x_train_path = \"/root/HAR/dataset/PAMAP2/x_train.npy\"\n","y_train_path = \"/root/HAR/dataset/PAMAP2/y_train.npy\"\n","# x_test_path = \"/kaggle/input/wisdm-data/wisdm/x_test.npy\"\n","# y_test_path = \"/kaggle/input/wisdm-data/wisdm/y_test.npy\"\n","x_test_path = \"/root/HAR/dataset/PAMAP2/x_test.npy\"\n","y_test_path = \"/root/HAR/dataset/PAMAP2/y_test.npy\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:01.126163Z","iopub.status.busy":"2024-02-11T06:21:01.125884Z","iopub.status.idle":"2024-02-11T06:21:04.273964Z","shell.execute_reply":"2024-02-11T06:21:04.273176Z","shell.execute_reply.started":"2024-02-11T06:21:01.126139Z"},"metadata":{},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SEModule(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.fc1 = nn.Conv1d(channels, channels // reduction, kernel_size=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv1d(channels // reduction, channels, kernel_size=1, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        y = self.avg_pool(x)\n","        y = self.fc1(y)\n","        y = self.relu(y)\n","        y = self.fc2(y)\n","        y = self.sigmoid(y)\n","        return x * y\n","\n","\n","class ChannelAttention1d(nn.Module):\n","\n","    def __init__(self, in_channels, ratio=16):\n","        super(ChannelAttention1d, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.max_pool = nn.AdaptiveMaxPool1d(1)\n","\n","        self.fc1 = nn.Conv1d(in_channels, in_channels//16, 1, bias=False)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Conv1d(in_channels//16, in_channels, 1, bias=False)\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n","        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n","        out = avg_out + max_out\n","        return self.sigmoid(out)\n","\n","class SpatialAttention1d(nn.Module):\n","\n","    def __init__(self, kernel_size=3):\n","        super(SpatialAttention1d, self).__init__()\n","        self.conv = nn.Conv1d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv(x)\n","        return self.sigmoid(x)\n","\n","class rSoftMax(nn.Module):\n","    def __init__(self, radix, cardinality):\n","        super().__init__()\n","        self.radix = radix\n","        self.cardinality = cardinality\n","\n","    def forward(self, x):\n","        if self.radix > 1:\n","            batch = x.size(0)\n","            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n","            x = F.softmax(x, dim=1)\n","            x = x.reshape(batch, -1)\n","        else:\n","            x = torch.sigmoid(x)\n","        return x\n","\n","\n","class DropBlock1D(object):\n","    def __init__(self, *args, **kwargs):\n","        raise NotImplementedError\n","\n","\n","class SplAtConv1d(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            channels,\n","            kernel_size,\n","            stride=1,\n","            padding=0,\n","            dilation=1,\n","            groups=1,\n","            bias=True,\n","            radix=2,\n","            reduction_factor=4,\n","            norm_layer=None,\n","            dropblock_prob=0.0,\n","            **kwargs,\n","\n","    ):\n","        super().__init__()\n","\n","        self.dropblock_prob = dropblock_prob\n","        inter_channels = max(in_channels * radix // reduction_factor, 32)\n","        self.radix = radix\n","        self.cardinality = groups\n","        self.channels = channels\n","\n","        self.conv = nn.Conv1d(\n","            in_channels,\n","            channels * radix,\n","            kernel_size,\n","            stride,\n","            padding,\n","            dilation,\n","            groups=groups * radix,\n","            bias=bias,\n","            **kwargs,\n","        )\n","        self.bn0 = norm_layer(self.channels * radix)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc1 = nn.Conv1d(self.channels, inter_channels, 1, groups=self.cardinality)\n","        self.bn1 = norm_layer(inter_channels)\n","        self.fc2 = nn.Conv1d(inter_channels, self.channels * radix, 1, groups=self.cardinality)\n","        if dropblock_prob > 0.0:\n","            self.dropblock = DropBlock1D(dropblock_prob, 3)\n","        self.rsoftmax = rSoftMax(radix, self.cardinality)\n","        self.se = SEModule(in_channels)\n","        self.ca1 = ChannelAttention1d(in_channels)\n","        self.sa1 = SpatialAttention1d()\n","\n","    def forward(self, x):\n","        #x = self.ca1(x) * x\n","        #x=  self.sa1(x) * x\n","        #x = self.se(x) * x\n","        x = self.conv(x)\n","        x = self.bn0(x)\n","        if self.dropblock_prob > 0.0:\n","            x = self.dropblock(x)\n","        x = self.relu(x)\n","\n","        batch, rchannel = x.shape[:2]\n","        if self.radix > 1:\n","            splited = torch.split(x, int(rchannel // self.radix), dim=1)\n","            gap = sum(splited)\n","        else:\n","            gap = x\n","        #se放在这个位置结果非常好\n","        #位置1，通道注意力\n","        gap = self.ca1(gap) * gap\n","        #gap = self.sa1(gap) * gap\n","        #gap = self.se(gap) * gap\n","        gap = F.adaptive_avg_pool1d(gap, 1)\n","        gap = self.fc1(gap)\n","        gap = self.bn1(gap)\n","        gap = self.relu(gap)\n","\n","        atten = self.fc2(gap)\n","        atten = self.rsoftmax(atten).view(batch, -1, 1)\n","\n","        if self.radix > 1:\n","            attens = torch.split(atten, int(rchannel // self.radix), dim=1)\n","            outs = []\n","            for att, split in zip(attens, splited):\n","                outs.append(att * split)\n","            out = sum(outs)\n","        else:\n","            out = atten * x\n","       # out = self.se(out) * out\n","        #out = self.ca1(out) * out\n","        #out = self.sa1(out) * out\n","        return out.contiguous()\n","\n","\n","\n","\n","\n","class ResNeStBottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.275592Z","iopub.status.busy":"2024-02-11T06:21:04.275183Z","iopub.status.idle":"2024-02-11T06:21:04.334146Z","shell.execute_reply":"2024-02-11T06:21:04.333193Z","shell.execute_reply.started":"2024-02-11T06:21:04.275567Z"},"metadata":{},"trusted":true},"outputs":[],"source":["class SplAtConv1d_WithoutCA(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            channels,\n","            kernel_size,\n","            stride=1,\n","            padding=0,\n","            dilation=1,\n","            groups=1,\n","            bias=True,\n","            radix=2,\n","            reduction_factor=4,\n","            norm_layer=None,\n","            dropblock_prob=0.0,\n","            **kwargs,\n","\n","    ):\n","        super().__init__()\n","\n","        self.dropblock_prob = dropblock_prob\n","        inter_channels = max(in_channels * radix // reduction_factor, 32)\n","        self.radix = radix\n","        self.cardinality = groups\n","        self.channels = channels\n","\n","        self.conv = nn.Conv1d(\n","            in_channels,\n","            channels * radix,\n","            kernel_size,\n","            stride,\n","            padding,\n","            dilation,\n","            groups=groups * radix,\n","            bias=bias,\n","            **kwargs,\n","        )\n","        self.bn0 = norm_layer(self.channels * radix)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc1 = nn.Conv1d(self.channels, inter_channels, 1, groups=self.cardinality)\n","        self.bn1 = norm_layer(inter_channels)\n","        self.fc2 = nn.Conv1d(inter_channels, self.channels * radix, 1, groups=self.cardinality)\n","        if dropblock_prob > 0.0:\n","            self.dropblock = DropBlock1D(dropblock_prob, 3)\n","        self.rsoftmax = rSoftMax(radix, self.cardinality)\n","        self.se = SEModule(in_channels)\n","        self.ca1 = ChannelAttention1d(in_channels)\n","        self.sa1 = SpatialAttention1d()\n","\n","    def forward(self, x):\n","        #x = self.ca1(x) * x\n","        #x=  self.sa1(x) * x\n","        #x = self.se(x) * x\n","        x = self.conv(x)\n","        x = self.bn0(x)\n","        if self.dropblock_prob > 0.0:\n","            x = self.dropblock(x)\n","        x = self.relu(x)\n","\n","        batch, rchannel = x.shape[:2]\n","        if self.radix > 1:\n","            splited = torch.split(x, int(rchannel // self.radix), dim=1)\n","            gap = sum(splited)\n","        else:\n","            gap = x\n","        #se放在这个位置结果非常好\n","        #位置1，通道注意力\n","        #gap = self.ca1(gap) * gap\n","        #gap = self.sa1(gap) * gap\n","        #gap = self.se(gap) * gap\n","        gap = F.adaptive_avg_pool1d(gap, 1)\n","        gap = self.fc1(gap)\n","        gap = self.bn1(gap)\n","        gap = self.relu(gap)\n","\n","        atten = self.fc2(gap)\n","        atten = self.rsoftmax(atten).view(batch, -1, 1)\n","\n","        if self.radix > 1:\n","            attens = torch.split(atten, int(rchannel // self.radix), dim=1)\n","            outs = []\n","            for att, split in zip(attens, splited):\n","                outs.append(att * split)\n","            out = sum(outs)\n","        else:\n","            out = atten * x\n","       # out = self.se(out) * out\n","        #out = self.ca1(out) * out\n","        #out = self.sa1(out) * out\n","        return out.contiguous()\n","    \n","class ResNeStBottleneck_WithoutCA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d_WithoutCA(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","        #x=  self.sa1(x) * x\n","        out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNeStBottleneck_WithoutSA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        #out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","    \n","class ResNeStBottleneck_WithoutCASA(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes,\n","            planes,\n","            stride=1,\n","            downsample=None,\n","            radix=1,\n","            cardinality=1,\n","            bottleneck_width=64,\n","            avd=False,\n","            avd_first=False,\n","            dilation=1,\n","            is_first=False,\n","            norm_layer=None,\n","            last_gamma=False,\n","            dropblock_prob=0.0\n","    ):\n","        super().__init__()\n","        group_width = int(planes * (bottleneck_width / 64.0)) * cardinality\n","\n","        self.conv1 = nn.Conv1d(inplanes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(group_width)\n","        self.radix = radix\n","        self.avd = avd and (stride > 1 or is_first)\n","        self.avd_first = avd_first\n","        self.dropblock_prob = dropblock_prob\n","\n","        if self.avd:\n","            self.avd_layer = nn.AvgPool1d(3, stride, padding=1)\n","            stride = 1\n","        if dropblock_prob > 0.0:\n","            self.dropblock1 = DropBlock1D(dropblock_prob, 3)\n","            if radix == 1:\n","                self.dropblock2 = DropBlock1D(dropblock_prob, 3)\n","            self.dropblock3 = DropBlock1D(dropblock_prob, 3)\n","\n","        if radix >= 1:\n","            self.conv2 = SplAtConv1d_WithoutCA(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","                radix=radix,\n","                norm_layer=norm_layer,\n","                dropblock_prob=dropblock_prob\n","            )\n","        else:\n","            self.conv2 = nn.Conv1d(\n","                group_width,\n","                group_width,\n","                kernel_size=3,\n","                stride=stride,\n","                padding=dilation,\n","                dilation=dilation,\n","                groups=cardinality,\n","                bias=False,\n","            )\n","            self.bn2 = norm_layer(group_width)\n","\n","        self.conv3 = nn.Conv1d(group_width, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","\n","        if last_gamma:\n","            from torch.nn.init import zeros_\n","\n","            zeros_(self.bn3.weight)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.dilation = dilation\n","        self.stride = stride\n","        self.ca1 = ChannelAttention1d(group_width)\n","        self.sa1 = SpatialAttention1d()\n","\n","        self.se = SEModule(group_width)\n","        \n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        #x = self.ca1(x) * x\n","        #位置2，空间注意力\n","       \n","        #out = self.sa1(out) * out\n","        out = self.bn1(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock1(out)\n","        out = self.relu(out)\n","        if self.avd and self.avd_first:\n","            out = self.avd_layer(out)\n","        #out = self.ca1(out) * out\n","        #out=  self.sa1(out) * out\n","        #out = self.se(out) * out\n","        out = self.conv2(out)\n","        if self.radix == 0:\n","            out = self.bn2(out)\n","            if self.dropblock_prob > 0.0:\n","                out = self.dropblock2(out)\n","            out = self.relu(out)\n","\n","        if self.avd and not self.avd_first:\n","            out = self.avd_layer(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.dropblock_prob > 0.0:\n","            out = self.dropblock3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(residual)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.337683Z","iopub.status.busy":"2024-02-11T06:21:04.337155Z","iopub.status.idle":"2024-02-11T06:21:04.368434Z","shell.execute_reply":"2024-02-11T06:21:04.367520Z","shell.execute_reply.started":"2024-02-11T06:21:04.337657Z"},"metadata":{},"trusted":true},"outputs":[],"source":["class ResNeSt1d(nn.Module):\n","    def __init__(\n","            self,\n","            inchannels,\n","            block,\n","            layers,\n","            radix=1,\n","            groups=1,\n","            bottleneck_width=64,\n","            num_classes=1000,\n","            dilated=False,\n","            dilation=1,\n","            deep_stem=False,\n","            stem_width=32,\n","            avg_down=False,\n","            avd=False,\n","            avd_first=False,\n","            final_drop=0.0,\n","            last_gamma=False,\n","            norm_layer=nn.BatchNorm1d,\n","            dropblock_prob=0\n","    ):\n","        super().__init__()\n","\n","        self.cardinality = groups\n","        self.bottleneck_width = bottleneck_width\n","        # ResNet-D params\n","        self.inplanes = stem_width * 2 if deep_stem else 64\n","        self.avg_down = avg_down\n","        self.last_gamma = last_gamma\n","        # ResNeSt params\n","        self.radix = radix\n","        self.avd = avd\n","        self.avd_first = avd_first\n","        \n","        \n","        act = nn.ReLU\n","\n","        if deep_stem:\n","            self.conv1 = nn.Sequential(\n","                nn.Conv1d(inchannels, stem_width, 3, 2, 1, bias=False),\n","                norm_layer(stem_width),\n","                act(inplace=True),\n","                nn.Conv1d(stem_width, stem_width, 3, 1, 1, bias=False),\n","                norm_layer(stem_width),\n","                act(inplace=True),\n","                nn.Conv1d(stem_width, self.inplanes, 3, 1, 1, bias=False),\n","            )\n","        else:\n","            self.conv1 = nn.Conv1d(inchannels, self.inplanes, 7, 2, 3, bias=False)\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = act(inplace=True)\n","        self.maxpool = nn.MaxPool1d(3, 2, 1)\n","        b = 16\n","        Blist = [b * 2, b * 4, b * 8, b * 16]\n","        self.layer1 = self._make_layer(block, Blist[0], layers[0], norm_layer=norm_layer, is_first=False)\n","        self.layer2 = self._make_layer(block, Blist[1], layers[1], stride=2, norm_layer=norm_layer)\n","        if dilated or dilation == 4:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=1, dilation=2, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            # self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=1, dilation=2, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","        elif dilation == 2:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=2, dilation=1, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            # self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=1, dilation=2, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","        else:\n","            self.layer3 = self._make_layer(block, Blist[2], layers[2], stride=2, dilation=1, norm_layer=norm_layer,\n","                                           dropblock_prob=dropblock_prob)\n","            self.layer4 = self._make_layer(block, Blist[3], layers[2], stride=2, dilation=1, norm_layer=norm_layer,dropblock_prob=dropblock_prob)\n","\n","        self.avgpool = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.Flatten())\n","        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n","        self.fc = nn.Linear(Blist[2] * block.expansion*2, num_classes)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None, is_first=True,\n","                    dropblock_prob=0.0):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            down_layers = []\n","            if self.avg_down:\n","                if dilation == 1:\n","                    down_layers.append(nn.AvgPool1d(stride, stride, ceil_mode=True, count_include_pad=False))\n","                else:\n","                    down_layers.append(nn.AvgPool1d(1, 1, ceil_mode=True, count_include_pad=False))\n","                down_layers.append(nn.Conv1d(self.inplanes, planes * block.expansion, 1, 1, 0, bias=False))\n","            else:\n","                down_layers.append(nn.Conv1d(self.inplanes, planes * block.expansion, 1, stride, 0, bias=False))\n","\n","            down_layers.append(norm_layer(planes * block.expansion))\n","            downsample = nn.Sequential(*down_layers)\n","\n","        layers = []\n","        if dilation == 1 or dilation == 2:\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    stride,\n","                    downsample=downsample,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=1,\n","                    is_first=is_first,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","        elif dilation == 4:\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    stride,\n","                    downsample=downsample,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=2,\n","                    is_first=is_first,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","        else:\n","            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n","\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    radix=self.radix,\n","                    cardinality=self.cardinality,\n","                    bottleneck_width=self.bottleneck_width,\n","                    avd=self.avd,\n","                    avd_first=self.avd_first,\n","                    dilation=dilation,\n","                    norm_layer=norm_layer,\n","                    last_gamma=self.last_gamma,\n","                    dropblock_prob=dropblock_prob\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = x.permute(0, -1, 1)\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","        x = self.avgpool(x)\n","        \n","        if self.drop:\n","            x = self.drop(x)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def resnest_t(inchannels,block, **kwargs):\n","    model = ResNeSt1d(\n","        inchannels,\n","        block,\n","        [2, 2, 3, 3],\n","        radix=4,\n","        groups=4,\n","        bottleneck_width=8,\n","        deep_stem=True,\n","        #wisdm = 16, pamp2 = 32\n","        stem_width=32,\n","        avg_down=True,\n","        avd=True,\n","        avd_first=False,\n","        **kwargs,\n","    )\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"metadata":{}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","class CustomDataset(Dataset):\n","    def __init__(self, x_path, y_path, transform=None):\n","        \n","        self.x_data = np.load(x_path)\n","        self.x_data = self.x_data[:, :, [0, 1, 2]]\n","        self.y_data = np.load(y_path)\n","\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.x_data)\n","\n","    def __getitem__(self, idx):\n","        \n","        x = self.x_data[idx]\n","        y = self.y_data[idx]\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        return x, y"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.370245Z","iopub.status.busy":"2024-02-11T06:21:04.369862Z","iopub.status.idle":"2024-02-11T06:21:04.395549Z","shell.execute_reply":"2024-02-11T06:21:04.394739Z","shell.execute_reply.started":"2024-02-11T06:21:04.370195Z"},"metadata":{},"trusted":true},"outputs":[],"source":["import copy\n","import time\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import pandas as pd\n","\n","\n","\n","#删除1\n","class LabelSmoothingCrossEntropy(nn.Module):\n","    \"\"\" NLL loss with label smoothing.\n","    \"\"\"\n","    def __init__(self, smoothing=0.1):\n","        super(LabelSmoothingCrossEntropy, self).__init__()\n","        assert smoothing < 1.0\n","        self.smoothing = smoothing\n","        self.confidence = 1. - smoothing\n","\n","    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n","        logprobs = F.log_softmax(input, dim=-1)\n","        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1).to(torch.int64))\n","        nll_loss = nll_loss.squeeze(1)\n","        smooth_loss = -logprobs.mean(dim=-1)\n","        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n","        return loss.mean()\n","class ClassBalancedLoss(nn.Module):\n","\n","    def __init__(self, num_classes, beta):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.beta = beta\n","\n","    def forward(self, inputs, targets):\n","        inputs = inputs.float()\n","        targets = targets.long()\n","        loss = F.cross_entropy(inputs, targets)\n","\n","        return self.beta * loss\n","\n","#删除2\n","class FocalLoss(nn.Module):\n","\n","    def __init__(self, alpha=0.25, gamma=2):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, inputs, targets):\n","        inputs = inputs.float()\n","        targets = targets.long()\n","\n","        ce_loss = F.cross_entropy(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","\n","        focal_loss = ((1-pt)**self.gamma * ce_loss)\n","\n","        return focal_loss\n","#删除3\n","class MultiLoss(nn.Module):\n","    def __init__(self, num_classes, beta, weights, smoothing=0.15):\n","        super().__init__()\n","\n","        # Replace ClassBalancedLoss with LabelSmoothingLoss\n","        self.label_smoothing_loss = LabelSmoothingCrossEntropy(smoothing=0.1)\n","        self.focal_loss = FocalLoss()\n","        self.ce_loss=ClassBalancedLoss(num_classes,beta)\n","        self.weights = weights\n","\n","    def forward(self, inputs, targets):\n","        loss1 = self.weights[0] * self.label_smoothing_loss(inputs, targets)\n","        loss2 = self.weights[1] * self.focal_loss(inputs, targets)\n","        loss3 = self.weights[2] * self.ce_loss(inputs, targets)\n","        return loss1 + loss2 + loss3\n","    #删除4\n","    def update_weights(self, epoch, performance_metrics):\n","        # 根据验证准确率调整权重\n","        task1_acc = performance_metrics.get(\"task1\", 0.0)\n","        task2_acc = performance_metrics.get(\"task2\", 0.0)\n","        task3_acc = performance_metrics.get(\"task3\", 0.0)\n","\n","        # 根据验证准确率的倒数来调整权重\n","        # 准确率越高的任务将获得较小的权重，反之亦然\n","        self.weights[0] = 0.5*(1-self.weights[1])\n","        self.weights[1] = 1-(1.0 / (task1_acc + 1e-8)-1)-a\n","        self.weights[2] = 0.5*(1-self.weights[1])\n","\n","        print(f\"Epoch {epoch}: 更新权重 - 任务1: {self.weights[0]}, 任务2: {self.weights[1]},任务3: {self.weights[2]}\")\n","\n","class MultiLoss_Withoutweight(nn.Module):\n","    def __init__(self, num_classes, beta, weights, smoothing=0.15):\n","        super().__init__()\n","\n","        # Replace ClassBalancedLoss with LabelSmoothingLoss\n","        self.label_smoothing_loss = LabelSmoothingCrossEntropy(smoothing=0.1)\n","        self.focal_loss = FocalLoss()\n","        self.ce_loss=ClassBalancedLoss(num_classes,beta)\n","        self.weights = weights\n","\n","    def forward(self, inputs, targets):\n","        loss1 = self.label_smoothing_loss(inputs, targets)\n","        loss2 = self.focal_loss(inputs, targets)\n","        loss3 = self.ce_loss(inputs, targets)\n","        return loss1 + loss2 + loss3\n","\n","        \n","        \n"," #删除5       \n","def compute_validation_accuracy(model, val_dataloader, device):\n","    model.eval()\n","    corrects = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            corrects += (predicted == labels).sum().item()\n","\n","    accuracy = corrects / total\n","    return accuracy"]},{"cell_type":"code","execution_count":8,"metadata":{"metadata":{}},"outputs":[],"source":["pamp2_b =128\n","wisdm_b = 512\n","def train_val_data_process():\n","    # 训练数据集的路径\n","\n","\n","    train_dataset = CustomDataset(x_train_path, y_train_path)\n","\n","    # 将数据集拆分为训练集和验证集\n","    train_size = int(0.8 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","    # 定义训练集和验证集的数据加载器\n","\n","    train_dataloader = DataLoader(train_data, batch_size=pamp2_b, shuffle=True, num_workers=2)#wisdm  batch_size=256  pamp2  batch_size=128\n","    val_dataloader = DataLoader(val_data, batch_size=pamp2_b, shuffle=True, num_workers=2)#wisdm  batch_size=256  pamp2  batch_size=128\n","\n","    return train_dataloader, val_dataloader"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.397104Z","iopub.status.busy":"2024-02-11T06:21:04.396766Z","iopub.status.idle":"2024-02-11T06:21:04.423874Z","shell.execute_reply":"2024-02-11T06:21:04.422906Z","shell.execute_reply.started":"2024-02-11T06:21:04.397074Z"},"metadata":{},"trusted":true},"outputs":[],"source":["\n","\n","\n","\n","def train_model_process(model, train_dataloader, val_dataloader, num_epochs,criterion):\n","    # 设定训练所用到的设备，有GPU用GPU没有GPU用CPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # 使用Adam优化器，学习率为0.001\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)#wisdm0.005  pamp2  0.01\n","\n","    # 将模型放入到训练设备中\n","    model = model.to(device)\n","    # 复制当前模型的参数\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    # 初始化参数\n","    # 最高准确度\n","    best_acc = 0.0\n","    # 训练集损失列表\n","    train_loss_all = []\n","    # 验证集损失列表\n","    val_loss_all = []\n","    # 训练集准确度列表\n","    train_acc_all = []\n","    # 验证集准确度列表\n","    val_acc_all = []\n","    # 当前时间\n","    since = time.time()\n","    #删除6\n","    multi_loss = MultiLoss(num_classes, beta, weights)\n","\n","\n","    for epoch in range(num_epochs):\n","        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n","        print(\"-\" * 10)\n","\n","        # 初始化参数\n","        # 训练集损失函数\n","        train_loss = 0.0\n","        # 训练集准确度\n","        train_corrects = 0\n","        # 验证集损失函数\n","        val_loss = 0.0\n","        # 验证集准确度\n","        val_corrects = 0\n","        # 训练集样本数量\n","        train_num = 0\n","        # 验证集样本数量\n","        val_num = 0\n","\n","        # 对每一个mini-batch训练和计算\n","        for step, (b_x, b_y) in enumerate(train_dataloader):\n","            # 将特征放入到训练设备中\n","            b_x = b_x.to(device)\n","            # 将标签放入到训练设备中\n","            b_y = b_y.to(device)\n","            # 设置模型为训练模式\n","            model.train()\n","\n","            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n","            output = model(b_x)\n","            # 查找每一行中最大值对应的行标\n","            pre_lab = torch.argmax(output, dim=1)\n","            # 计算每一个batch的损失函数\n","            loss = criterion(output, b_y)\n","\n","            # 将梯度初始化为0\n","            optimizer.zero_grad()\n","            # 反向传播计算\n","            loss.backward()\n","            # 根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值的作用\n","            optimizer.step()\n","            # 对损失函数进行累加\n","            train_loss += loss.item() * b_x.size(0)\n","            # 如果预测正确，则准确度train_corrects加1\n","            train_corrects += torch.sum(pre_lab == b_y.data)\n","            # 当前用于训练的样本数量\n","            train_num += b_x.size(0)\n","        for step, (b_x, b_y) in enumerate(val_dataloader):\n","            # 将特征放入到验证设备中\n","            b_x = b_x.to(device)\n","            # 将标签放入到验证设备中\n","            b_y = b_y.to(device)\n","            # 设置模型为评估模式\n","            model.eval()\n","            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n","            output = model(b_x)\n","            # 查找每一行中最大值对应的行标\n","            pre_lab = torch.argmax(output, dim=1)\n","            # 计算每一个batch的损失函数\n","            loss = criterion(output, b_y)\n","\n","            # 对损失函数进行累加\n","            val_loss += loss.item() * b_x.size(0)\n","            # 如果预测正确，则准确度train_corrects加1\n","            val_corrects += torch.sum(pre_lab == b_y.data)\n","            # 当前用于验证的样本数量\n","            val_num += b_x.size(0)\n","\n","        # 计算并保存每一次迭代的loss值和准确率\n","        # 计算并保存训练集的loss值\n","        train_loss_all.append(train_loss / train_num)\n","        # 计算并保存训练集的准确率\n","        train_acc_all.append(train_corrects.double().item() / train_num)\n","\n","        # 计算并保存验证集的loss值\n","        val_loss_all.append(val_loss / val_num)\n","        # 计算并保存验证集的准确率\n","        val_acc_all.append(val_corrects.double().item() / val_num)\n","\n","        print(\"{} train loss:{:.4f} train acc: {:.4f}\".format(epoch, train_loss_all[-1], train_acc_all[-1]))\n","        print(\"{} val loss:{:.4f} val acc: {:.4f}\".format(epoch, val_loss_all[-1], val_acc_all[-1]))\n","\n","        if val_acc_all[-1] > best_acc:\n","            # 保存当前最高准确度\n","            best_acc = val_acc_all[-1]\n","            # 保存当前最高准确度的模型参数\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        # 计算训练和验证的耗时\n","        time_use = time.time() - since\n","        print(\"训练和验证耗费的时间{:.0f}m{:.0f}s\".format(time_use // 60, time_use % 60))\n","        #删除7\n","        val_acc_task1 = compute_validation_accuracy(model, val_dataloader, device)\n","        val_acc_task2 = compute_validation_accuracy(model, val_dataloader, device)\n","        val_acc_task3 = compute_validation_accuracy(model, val_dataloader, device)\n","        multi_loss.update_weights(epoch, {\"task1\": val_acc_task1, \"task2\": val_acc_task2, \"task3\": val_acc_task3})\n","        multi_loss = MultiLoss(num_classes, beta, multi_loss.weights)\n","\n"," \n","\n","    # 选择最优参数，保存最优参数的模型\n","    print(best_acc)\n","    train_process = pd.DataFrame(data={\"epoch\": range(num_epochs),\n","                                       \"train_loss_all\": train_loss_all,\n","                                       \"val_loss_all\": val_loss_all,\n","                                       \"train_acc_all\": train_acc_all,\n","                                       \"val_acc_all\": val_acc_all, })\n","\n","    return train_process\n","\n","\n","def matplot_acc_loss(train_process):\n","    # 显示每一次迭代后的训练集和验证集的损失函数和准确率\n","    plt.figure(figsize=(12, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(train_process['epoch'], train_process.train_loss_all, \"ro-\", label=\"Train loss\")\n","    plt.plot(train_process['epoch'], train_process.val_loss_all, \"bs-\", label=\"Val loss\")\n","    plt.legend()\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.subplot(1, 2, 2)\n","    plt.plot(train_process['epoch'], train_process.train_acc_all, \"ro-\", label=\"Train acc\")\n","    plt.plot(train_process['epoch'], train_process.val_acc_all, \"bs-\", label=\"Val acc\")\n","    plt.xlabel(\"epoch\")\n","    plt.ylabel(\"acc\")\n","    plt.legend()\n","    plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T06:21:04.425257Z","iopub.status.busy":"2024-02-11T06:21:04.424958Z","iopub.status.idle":"2024-02-11T06:23:31.743996Z","shell.execute_reply":"2024-02-11T06:23:31.742485Z","shell.execute_reply.started":"2024-02-11T06:21:04.425206Z"},"metadata":{},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/49\n","----------\n","0 train loss:1.7581 train acc: 0.4925\n","0 val loss:2.3816 val acc: 0.4615\n","训练和验证耗费的时间0m3s\n","Epoch 0: 更新权重 - 任务1: 0.25, 任务2: -0.616666619722223,任务3: 0.8083333098611115\n","Epoch 1/49\n","----------\n","1 train loss:1.0643 train acc: 0.6344\n","1 val loss:0.9309 val acc: 0.6814\n","训练和验证耗费的时间0m6s\n","Epoch 1: 更新权重 - 任务1: 0.8083333098611115, 任务2: 0.082497170908508,任务3: 0.458751414545746\n","Epoch 2/49\n","----------\n","2 train loss:1.5536 train acc: 0.7418\n","2 val loss:2.6897 val acc: 0.5859\n","训练和验证耗费的时间0m9s\n","Epoch 2: 更新权重 - 任务1: 0.458751414545746, 任务2: -0.1568965225891799,任务3: 0.5784482612945899\n","Epoch 3/49\n","----------\n","3 train loss:0.9575 train acc: 0.7935\n","3 val loss:0.9210 val acc: 0.7887\n","训练和验证耗费的时间0m11s\n","Epoch 3: 更新权重 - 任务1: 0.5784482612945899, 任务2: 0.28201972051123775,任务3: 0.3589901397443811\n","Epoch 4/49\n","----------\n","4 train loss:0.9071 train acc: 0.8209\n","4 val loss:1.0731 val acc: 0.7591\n","训练和验证耗费的时间0m14s\n","Epoch 4: 更新权重 - 任务1: 0.3589901397443811, 任务2: 0.23270216678978833,任务3: 0.3836489166051058\n","Epoch 5/49\n","----------\n","5 train loss:0.8730 train acc: 0.7329\n","5 val loss:0.7829 val acc: 0.7731\n","训练和验证耗费的时间0m17s\n","Epoch 5: 更新权重 - 任务1: 0.3836489166051058, 任务2: 0.2565326800471603,任务3: 0.37173365997641983\n","Epoch 6/49\n","----------\n","6 train loss:0.6637 train acc: 0.8209\n","6 val loss:0.6120 val acc: 0.8407\n","训练和验证耗费的时间0m20s\n","Epoch 6: 更新权重 - 任务1: 0.37173365997641983, 任务2: 0.360536058510537,任务3: 0.3197319707447315\n","Epoch 7/49\n","----------\n","7 train loss:0.5545 train acc: 0.8554\n","7 val loss:0.6845 val acc: 0.8159\n","训练和验证耗费的时间0m23s\n","Epoch 7: 更新权重 - 任务1: 0.3197319707447315, 任务2: 0.32428572930946936,任务3: 0.3378571353452653\n","Epoch 8/49\n","----------\n","8 train loss:0.4872 train acc: 0.8654\n","8 val loss:0.7955 val acc: 0.7607\n","训练和验证耗费的时间0m26s\n","Epoch 8: 更新权重 - 任务1: 0.3378571353452653, 任务2: 0.23539327570887497,任务3: 0.3823033621455625\n","Epoch 9/49\n","----------\n","9 train loss:0.5654 train acc: 0.8496\n","9 val loss:0.5704 val acc: 0.8415\n","训练和验证耗费的时间0m29s\n","Epoch 9: 更新权重 - 任务1: 0.3823033621455625, 任务2: 0.36163436315260017,任务3: 0.3191828184236999\n","Epoch 10/49\n","----------\n","10 train loss:0.5011 train acc: 0.8883\n","10 val loss:0.4957 val acc: 0.8889\n","训练和验证耗费的时间0m32s\n","Epoch 10: 更新权重 - 任务1: 0.3191828184236999, 任务2: 0.4250000126562498,任务3: 0.28749999367187506\n","Epoch 11/49\n","----------\n","11 train loss:0.4156 train acc: 0.8953\n","11 val loss:0.4504 val acc: 0.8687\n","训练和验证耗费的时间0m35s\n","Epoch 11: 更新权重 - 任务1: 0.28749999367187506, 任务2: 0.3988372225540832,任务3: 0.30058138872295836\n","Epoch 12/49\n","----------\n","12 train loss:0.3671 train acc: 0.9056\n","12 val loss:0.3762 val acc: 0.8920\n","训练和验证耗费的时间0m38s\n","Epoch 12: 更新权重 - 任务1: 0.30058138872295836, 任务2: 0.42891987319538444,任务3: 0.28554006340230775\n","Epoch 13/49\n","----------\n","13 train loss:0.3539 train acc: 0.9186\n","13 val loss:0.3741 val acc: 0.9021\n","训练和验证耗费的时间0m41s\n","Epoch 13: 更新权重 - 任务1: 0.28554006340230775, 任务2: 0.4414728805053782,任务3: 0.2792635597473109\n","Epoch 14/49\n","----------\n","14 train loss:0.3515 train acc: 0.9075\n","14 val loss:0.3668 val acc: 0.9052\n","训练和验证耗费的时间0m43s\n","Epoch 14: 更新权重 - 任务1: 0.2792635597473109, 任务2: 0.44527898216116685,任务3: 0.27736050891941655\n","Epoch 15/49\n","----------\n","15 train loss:0.3359 train acc: 0.9149\n","15 val loss:0.3964 val acc: 0.8866\n","训练和验证耗费的时间0m46s\n","Epoch 15: 更新权重 - 任务1: 0.27736050891941655, 任务2: 0.4220420810839777,任务3: 0.2889789594580111\n","Epoch 16/49\n","----------\n","16 train loss:0.3379 train acc: 0.9122\n","16 val loss:0.3627 val acc: 0.8951\n","训练和验证耗费的时间0m49s\n","Epoch 16: 更新权重 - 任务1: 0.2889789594580111, 任务2: 0.43281251248107905,任务3: 0.28359374375946045\n","Epoch 17/49\n","----------\n","17 train loss:0.3187 train acc: 0.9275\n","17 val loss:0.3480 val acc: 0.9153\n","训练和验证耗费的时间0m52s\n","Epoch 17: 更新权重 - 任务1: 0.28359374375946045, 任务2: 0.4574703005609994,任务3: 0.27126484971950027\n","Epoch 18/49\n","----------\n","18 train loss:0.3114 train acc: 0.9258\n","18 val loss:0.3542 val acc: 0.8974\n","训练和验证耗费的时间0m54s\n","Epoch 18: 更新权重 - 任务1: 0.27126484971950027, 任务2: 0.4357142981306123,任务3: 0.2821428509346938\n","Epoch 19/49\n","----------\n","19 train loss:0.3078 train acc: 0.9215\n","19 val loss:0.3509 val acc: 0.8974\n","训练和验证耗费的时间0m57s\n","Epoch 19: 更新权重 - 任务1: 0.2821428509346938, 任务2: 0.4357142981306123,任务3: 0.2821428509346938\n","Epoch 20/49\n","----------\n","20 train loss:0.3035 train acc: 0.9266\n","20 val loss:0.3434 val acc: 0.9037\n","训练和验证耗费的时间1m0s\n","Epoch 20: 更新权重 - 任务1: 0.2821428509346938, 任务2: 0.44337920399158176,任务3: 0.2783103980042091\n","Epoch 21/49\n","----------\n","21 train loss:0.2977 train acc: 0.9314\n","21 val loss:0.4848 val acc: 0.8889\n","训练和验证耗费的时间1m3s\n","Epoch 21: 更新权重 - 任务1: 0.2783103980042091, 任务2: 0.4250000126562498,任务3: 0.28749999367187506\n","Epoch 22/49\n","----------\n","22 train loss:0.3110 train acc: 0.9260\n","22 val loss:0.3957 val acc: 0.8819\n","训练和验证耗费的时间1m6s\n","Epoch 22: 更新权重 - 任务1: 0.28749999367187506, 任务2: 0.4160793080119464,任务3: 0.29196034599402676\n","Epoch 23/49\n","----------\n","23 train loss:0.3310 train acc: 0.9201\n","23 val loss:0.3816 val acc: 0.8842\n","训练和验证耗费的时间1m9s\n","Epoch 23: 更新权重 - 任务1: 0.29196034599402676, 任务2: 0.4190685540905867,任务3: 0.29046572295470663\n","Epoch 24/49\n","----------\n","24 train loss:0.3394 train acc: 0.9147\n","24 val loss:0.3745 val acc: 0.9029\n","训练和验证耗费的时间1m12s\n","Epoch 24: 更新权重 - 任务1: 0.29046572295470663, 任务2: 0.4424268625253584,任务3: 0.2787865687373208\n","Epoch 25/49\n","----------\n","25 train loss:0.3402 train acc: 0.9137\n","25 val loss:0.3671 val acc: 0.8974\n","训练和验证耗费的时间1m14s\n","Epoch 25: 更新权重 - 任务1: 0.2787865687373208, 任务2: 0.4357142981306123,任务3: 0.2821428509346938\n","Epoch 26/49\n","----------\n","26 train loss:0.3055 train acc: 0.9271\n","26 val loss:0.3403 val acc: 0.9099\n","训练和验证耗费的时间1m17s\n","Epoch 26: 更新权重 - 任务1: 0.2821428509346938, 任务2: 0.4509393801408285,任务3: 0.2745303099295857\n","Epoch 27/49\n","----------\n","27 train loss:0.3434 train acc: 0.9071\n","27 val loss:0.3579 val acc: 0.9052\n","训练和验证耗费的时间1m20s\n","Epoch 27: 更新权重 - 任务1: 0.2745303099295857, 任务2: 0.44527898216116685,任务3: 0.27736050891941655\n","Epoch 28/49\n","----------\n","28 train loss:0.3003 train acc: 0.9275\n","28 val loss:0.3620 val acc: 0.8928\n","训练和验证耗费的时间1m23s\n","Epoch 28: 更新权重 - 任务1: 0.27736050891941655, 任务2: 0.4298955739040417,任务3: 0.2850522130479791\n","Epoch 29/49\n","----------\n","29 train loss:0.3162 train acc: 0.9190\n","29 val loss:0.3981 val acc: 0.8842\n","训练和验证耗费的时间1m25s\n","Epoch 29: 更新权重 - 任务1: 0.2850522130479791, 任务2: 0.4190685540905867,任务3: 0.29046572295470663\n","Epoch 30/49\n","----------\n","30 train loss:0.3173 train acc: 0.9262\n","30 val loss:0.4436 val acc: 0.8570\n","训练和验证耗费的时间1m28s\n","Epoch 30: 更新权重 - 任务1: 0.29046572295470663, 任务2: 0.3831822438956886,任务3: 0.30840887805215567\n","Epoch 31/49\n","----------\n","31 train loss:0.3948 train acc: 0.8908\n","31 val loss:0.3914 val acc: 0.8920\n","训练和验证耗费的时间1m31s\n","Epoch 31: 更新权重 - 任务1: 0.30840887805215567, 任务2: 0.42891987319538444,任务3: 0.28554006340230775\n","Epoch 32/49\n","----------\n","32 train loss:0.3555 train acc: 0.9120\n","32 val loss:0.3645 val acc: 0.9122\n","训练和验证耗费的时间1m34s\n","Epoch 32: 更新权重 - 任务1: 0.28554006340230775, 任务2: 0.4537478825457963,任务3: 0.27312605872710183\n","Epoch 33/49\n","----------\n","33 train loss:0.3000 train acc: 0.9293\n","33 val loss:0.3272 val acc: 0.9114\n","训练和验证耗费的时间1m37s\n","Epoch 33: 更新权重 - 任务1: 0.27312605872710183, 任务2: 0.4528133112709231,任务3: 0.2735933443645384\n","Epoch 34/49\n","----------\n","34 train loss:0.2816 train acc: 0.9343\n","34 val loss:0.3104 val acc: 0.9169\n","训练和验证耗费的时间1m39s\n","Epoch 34: 更新权重 - 任务1: 0.2735933443645384, 任务2: 0.45932204579408936,任务3: 0.2703389771029553\n","Epoch 35/49\n","----------\n","35 train loss:0.2744 train acc: 0.9369\n","35 val loss:0.3301 val acc: 0.9060\n","训练和验证耗费的时间1m42s\n","Epoch 35: 更新权重 - 任务1: 0.2703389771029553, 任务2: 0.4462264272775009,任务3: 0.2768867863612495\n","Epoch 36/49\n","----------\n","36 train loss:0.2745 train acc: 0.9384\n","36 val loss:0.3169 val acc: 0.9169\n","训练和验证耗费的时间1m45s\n","Epoch 36: 更新权重 - 任务1: 0.2768867863612495, 任务2: 0.45932204579408936,任务3: 0.2703389771029553\n","Epoch 37/49\n","----------\n","37 train loss:0.2610 train acc: 0.9495\n","37 val loss:0.3271 val acc: 0.9161\n","训练和验证耗费的时间1m48s\n","Epoch 37: 更新权重 - 任务1: 0.2703389771029553, 任务2: 0.45839695848085754,任务3: 0.2708015207595712\n","Epoch 38/49\n","----------\n","38 train loss:0.2605 train acc: 0.9398\n","38 val loss:0.3034 val acc: 0.9254\n","训练和验证耗费的时间1m51s\n","Epoch 38: 更新权重 - 任务1: 0.2708015207595712, 任务2: 0.46939547767202366,任务3: 0.26530226116398814\n","Epoch 39/49\n","----------\n","39 train loss:0.2564 train acc: 0.9458\n","39 val loss:0.3282 val acc: 0.9075\n","训练和验证耗费的时间1m53s\n","Epoch 39: 更新权重 - 任务1: 0.26530226116398814, 任务2: 0.4481164504976382,任务3: 0.27594177475118087\n","Epoch 40/49\n","----------\n","40 train loss:0.2425 train acc: 0.9551\n","40 val loss:0.3358 val acc: 0.9060\n","训练和验证耗费的时间1m56s\n","Epoch 40: 更新权重 - 任务1: 0.27594177475118087, 任务2: 0.4462264272775009,任务3: 0.2768867863612495\n","Epoch 41/49\n","----------\n","41 train loss:0.2550 train acc: 0.9522\n","41 val loss:0.3201 val acc: 0.9145\n","训练和验证耗费的时间1m59s\n","Epoch 41: 更新权重 - 任务1: 0.2768867863612495, 任务2: 0.456542068031269,任务3: 0.27172896598436547\n","Epoch 42/49\n","----------\n","42 train loss:0.2424 train acc: 0.9571\n","42 val loss:0.3378 val acc: 0.9005\n","训练和验证耗费的时间2m2s\n","Epoch 42: 更新权重 - 任务1: 0.27172896598436547, 任务2: 0.4395599778182599,任务3: 0.28022001109087\n","Epoch 43/49\n","----------\n","43 train loss:0.2398 train acc: 0.9592\n","43 val loss:0.3132 val acc: 0.9176\n","训练和验证耗费的时间2m5s\n","Epoch 43: 更新权重 - 任务1: 0.28022001109087, 任务2: 0.4602455664903808,任务3: 0.2698772167548096\n","Epoch 44/49\n","----------\n","44 train loss:0.2720 train acc: 0.9427\n","44 val loss:0.3226 val acc: 0.9184\n","训练和验证耗费的时间2m8s\n","Epoch 44: 更新权重 - 任务1: 0.2698772167548096, 任务2: 0.4611675245459172,任务3: 0.2694162377270414\n","Epoch 45/49\n","----------\n","45 train loss:0.2446 train acc: 0.9530\n","45 val loss:0.3045 val acc: 0.9231\n","训练和验证耗费的时间2m10s\n","Epoch 45: 更新权重 - 任务1: 0.2694162377270414, 任务2: 0.4666666784027777,任务3: 0.2666666607986111\n","Epoch 46/49\n","----------\n","46 train loss:0.2422 train acc: 0.9555\n","46 val loss:0.3680 val acc: 0.8951\n","训练和验证耗费的时间2m13s\n","Epoch 46: 更新权重 - 任务1: 0.2666666607986111, 任务2: 0.43281251248107905,任务3: 0.28359374375946045\n","Epoch 47/49\n","----------\n","47 train loss:0.2353 train acc: 0.9584\n","47 val loss:0.3486 val acc: 0.9075\n","训练和验证耗费的时间2m16s\n","Epoch 47: 更新权重 - 任务1: 0.28359374375946045, 任务2: 0.4481164504976382,任务3: 0.27594177475118087\n","Epoch 48/49\n","----------\n","48 train loss:0.3066 train acc: 0.9246\n","48 val loss:0.3410 val acc: 0.9029\n","训练和验证耗费的时间2m19s\n","Epoch 48: 更新权重 - 任务1: 0.27594177475118087, 任务2: 0.4424268625253584,任务3: 0.2787865687373208\n","Epoch 49/49\n","----------\n","49 train loss:0.3110 train acc: 0.9201\n","49 val loss:0.3939 val acc: 0.8726\n","训练和验证耗费的时间2m22s\n","Epoch 49: 更新权重 - 任务1: 0.2787865687373208, 任务2: 0.4039626133121114,任务3: 0.29801869334394426\n","0.9254079254079254\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1200x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# search pamp to find the differences and change\n","num_classes = 12 #pamp2 =12 wisdm =6\n","inchannels = 3 #pamp2 =36 wisdm =3\n","\n","#1\n","#model_n_casa = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutCASA)\n","#2\n","#model_n_ca = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutCA)\n","#3\n","#model_n_sa = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck_WithoutSA)\n","#4\n","model = resnest_t(inchannels=inchannels,num_classes=num_classes,block = ResNeStBottleneck)\n","\n","model = model\n","if __name__ == '__main__':\n","    # 加载需要的模型\n","    \n","    # 加载数据集\n","    train_data, val_data = train_val_data_process()\n","    # 利用现有的模型进行模型的训练\n","      # 替换为你的类别总数\n","    beta = 1  # 平衡系数  #wisdm\n","    #beta=0.8  #pamp2\n","    #weights = [0.1, 0.8,0.1] #wisdm\n","    a=0.45\n","    weights = [0.25, 0.5,0.25] #pamp2\n","    #4\n","    criterion1 = nn.CrossEntropyLoss()\n","    #5\n","    criterion2 = MultiLoss_Withoutweight(num_classes, beta, weights)\n","    #不测\n","    criterion3 = MultiLoss(num_classes, beta, weights,smoothing=0.1)#smoothing=0.15  #pamp2\n","\n","    train_process = train_model_process(model, train_data,val_data, num_epochs=50,criterion = criterion3)\n","    matplot_acc_loss(train_process)"]},{"cell_type":"code","execution_count":11,"metadata":{"metadata":{}},"outputs":[],"source":["torch.save(model, 'res_pamap2100_model.pt')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.status.busy":"2024-02-11T06:23:31.745275Z","iopub.status.idle":"2024-02-11T06:23:31.745648Z","shell.execute_reply":"2024-02-11T06:23:31.745490Z","shell.execute_reply.started":"2024-02-11T06:23:31.745473Z"},"metadata":{},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 1.1282, Test Acc: 72.10%, G-mean: 0.8048\n","              precision    recall  f1-score   support\n","\n","           0     0.0323    0.0110    0.0164        91\n","           1     0.4226    0.6827    0.5221       104\n","           2     0.6250    0.8235    0.7107        85\n","           3     0.7986    0.8952    0.8441       124\n","           4     0.9278    0.9474    0.9375        95\n","           5     0.9189    0.7158    0.8047        95\n","           6     0.9009    0.9804    0.9390       102\n","           7     0.7059    0.4364    0.5393        55\n","           8     0.8163    0.8333    0.8247        48\n","           9     0.9206    0.6170    0.7389        94\n","          10     0.6867    0.8047    0.7410       128\n","          11     0.9545    0.7241    0.8235        29\n","\n","    accuracy                         0.7210      1050\n","   macro avg     0.7258    0.7060    0.7035      1050\n","weighted avg     0.7109    0.7210    0.7044      1050\n","\n","G-mean: 0.8048\n"]}],"source":["import torch\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","import torch.nn as nn\n","\n","\n","def test_final(model, test_dataloader):\n","    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","    model = model.to(device)\n","    criterion1 = nn.CrossEntropyLoss()\n","    num_classes = 6\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)  \n","\n","    model.eval()\n","    test_loss = 0.0\n","    test_correct = 0\n","    test_total = 0\n","    y_true = []\n","    y_pred = []\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(test_dataloader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion1(outputs, labels)\n","            _, predicted = torch.max(outputs.data, 1)\n","            test_correct += (predicted == labels).sum().item()\n","            test_total += labels.size(0)\n","            test_loss += loss.item()\n","            y_true.extend(labels.tolist())\n","            y_pred.extend(predicted.tolist())\n","            conf_matrix += confusion_matrix(labels.cpu(), predicted.cpu(), labels=range(num_classes))\n","\n","    report = classification_report(y_true, y_pred,digits=4)\n","    test_acc = 100.0 * test_correct / test_total\n","    test_loss = test_loss / len(test_dataloader)\n","\n","    g_mean = np.sqrt(np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n","    g_mean = np.mean(g_mean)\n","    report += '\\nG-mean: {:.4f}'.format(g_mean)\n","    print('Test Loss: {:.4f}, Test Acc: {:.2f}%, G-mean: {:.4f}'.format(test_loss, test_acc, g_mean))\n","    print(report)\n","\n","\n","def test_data_process():\n","    test_data = CustomDataset(x_test_path, y_test_path)\n","    test_dataloader = DataLoader(test_data, batch_size=pamp2_b, shuffle=True, num_workers=2)\n","    return test_dataloader\n","\n","\n","def test_model_process(model, test_dataloader):\n","    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n","    model = model.to(device)\n","    classes = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n","\n","    test_corrects = 0.0\n","    test_num = 0\n","\n","    with torch.no_grad():\n","        for test_data_x, test_data_y in test_dataloader:\n","            test_data_x = test_data_x.to(device)\n","            test_data_y = test_data_y.to(device)\n","            model.eval()\n","            output = model(test_data_x)\n","            pre_lab = torch.argmax(output, dim=1)\n","            test_corrects += torch.sum(pre_lab == test_data_y.data)\n","            test_num += test_data_x.size(0)\n","\n","    test_acc = test_corrects.double().item() / test_num\n","    print(\"测试的准确率为：\", test_acc)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    model = torch.load('res_pamap2100_model.pt')\n","    test_dataloader = test_data_process()\n","    test_final(model, test_dataloader)\n","  \n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4183646,"sourceId":7226790,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
